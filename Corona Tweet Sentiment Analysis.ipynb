{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the data\n",
    "import os\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "dataDir = '/home/noah/Datasets/CoronaTweets'\n",
    "data = os.path.join(dataDir, 'coronaTest.csv')\n",
    "df = pd.read_csv(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['Location', 'UserName', 'ScreenName', 'TweetAt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRENDING: New Yorkers encounter empty supermar...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I couldn't find hand sanitizer at Fred Me...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Find out how you can protect yourself and love...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Panic buying hits #NewYork City as anxious sh...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#toiletpaper #dunnypaper #coronavirus #coronav...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3793</th>\n",
       "      <td>Meanwhile In A Supermarket in Israel -- People...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>Did you panic buy a lot of non-perishable item...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>Asst Prof of Economics @cconces was on @NBCPhi...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>Gov need to do somethings instead of biar je r...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>I and @ForestandPaper members are committed to...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3798 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          OriginalTweet           Sentiment\n",
       "0     TRENDING: New Yorkers encounter empty supermar...  Extremely Negative\n",
       "1     When I couldn't find hand sanitizer at Fred Me...            Positive\n",
       "2     Find out how you can protect yourself and love...  Extremely Positive\n",
       "3     #Panic buying hits #NewYork City as anxious sh...            Negative\n",
       "4     #toiletpaper #dunnypaper #coronavirus #coronav...             Neutral\n",
       "...                                                 ...                 ...\n",
       "3793  Meanwhile In A Supermarket in Israel -- People...            Positive\n",
       "3794  Did you panic buy a lot of non-perishable item...            Negative\n",
       "3795  Asst Prof of Economics @cconces was on @NBCPhi...             Neutral\n",
       "3796  Gov need to do somethings instead of biar je r...  Extremely Negative\n",
       "3797  I and @ForestandPaper members are committed to...  Extremely Positive\n",
       "\n",
       "[3798 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'to': 2,\n",
       " '\\r\\r': 3,\n",
       " 'and': 4,\n",
       " 'covid': 5,\n",
       " '19': 6,\n",
       " 'of': 7,\n",
       " 't': 8,\n",
       " 'in': 9,\n",
       " 'co': 10,\n",
       " 'a': 11,\n",
       " 'https': 12,\n",
       " 'coronavirus': 13,\n",
       " 'food': 14,\n",
       " 'for': 15,\n",
       " 'is': 16,\n",
       " 'i': 17,\n",
       " 'are': 18,\n",
       " 'on': 19,\n",
       " 'you': 20,\n",
       " 'store': 21,\n",
       " 'at': 22,\n",
       " 'this': 23,\n",
       " 'grocery': 24,\n",
       " 'stock': 25,\n",
       " 'people': 26,\n",
       " 'up': 27,\n",
       " 'be': 28,\n",
       " 'have': 29,\n",
       " 'that': 30,\n",
       " 'with': 31,\n",
       " 'we': 32,\n",
       " 'amp': 33,\n",
       " 'all': 34,\n",
       " 'or': 35,\n",
       " 'it': 36,\n",
       " 'my': 37,\n",
       " 'your': 38,\n",
       " 'not': 39,\n",
       " 'if': 40,\n",
       " 'shopping': 41,\n",
       " 'online': 42,\n",
       " 'supermarket': 43,\n",
       " 'out': 44,\n",
       " 'panic': 45,\n",
       " 'will': 46,\n",
       " 'as': 47,\n",
       " 'no': 48,\n",
       " 'from': 49,\n",
       " 'they': 50,\n",
       " 'prices': 51,\n",
       " 'but': 52,\n",
       " 'just': 53,\n",
       " 'so': 54,\n",
       " 'can': 55,\n",
       " 'about': 56,\n",
       " 'toilet': 57,\n",
       " 'need': 58,\n",
       " 'our': 59,\n",
       " 'paper': 60,\n",
       " 'like': 61,\n",
       " 'get': 62,\n",
       " 'now': 63,\n",
       " 'what': 64,\n",
       " 'more': 65,\n",
       " 'covid19': 66,\n",
       " 'their': 67,\n",
       " 'buying': 68,\n",
       " 'has': 69,\n",
       " 'who': 70,\n",
       " 'do': 71,\n",
       " 'by': 72,\n",
       " 'me': 73,\n",
       " 'was': 74,\n",
       " 'how': 75,\n",
       " 'going': 76,\n",
       " 'go': 77,\n",
       " 'some': 78,\n",
       " 'please': 79,\n",
       " 'local': 80,\n",
       " 'because': 81,\n",
       " 'retail': 82,\n",
       " 'us': 83,\n",
       " 'time': 84,\n",
       " 'an': 85,\n",
       " 'there': 86,\n",
       " 'when': 87,\n",
       " 'home': 88,\n",
       " 'shelves': 89,\n",
       " 'coronaviruspandemic': 90,\n",
       " 'buy': 91,\n",
       " 'stores': 92,\n",
       " 'consumer': 93,\n",
       " 'work': 94,\n",
       " 'everyone': 95,\n",
       " 'other': 96,\n",
       " 'due': 97,\n",
       " 'today': 98,\n",
       " 'over': 99,\n",
       " 'help': 100,\n",
       " '2': 101,\n",
       " 'covid2019': 102,\n",
       " 'demand': 103,\n",
       " 'supplies': 104,\n",
       " 'them': 105,\n",
       " 'only': 106,\n",
       " 'been': 107,\n",
       " 'one': 108,\n",
       " 'coronaoutbreak': 109,\n",
       " 'down': 110,\n",
       " 'don\\x92t': 111,\n",
       " 'virus': 112,\n",
       " 'these': 113,\n",
       " 'pandemic': 114,\n",
       " 'than': 115,\n",
       " 'during': 116,\n",
       " 'stay': 117,\n",
       " 'hand': 118,\n",
       " '1': 119,\n",
       " 'should': 120,\n",
       " 'those': 121,\n",
       " 'even': 122,\n",
       " 'here': 123,\n",
       " 'coronapocalypse': 124,\n",
       " 'water': 125,\n",
       " 'still': 126,\n",
       " 'empty': 127,\n",
       " 'being': 128,\n",
       " \"it's\": 129,\n",
       " 'went': 130,\n",
       " 'many': 131,\n",
       " 'would': 132,\n",
       " 'think': 133,\n",
       " 'day': 134,\n",
       " 'know': 135,\n",
       " 'it\\x92s': 136,\n",
       " 'take': 137,\n",
       " \"don't\": 138,\n",
       " 'see': 139,\n",
       " 'any': 140,\n",
       " 'make': 141,\n",
       " 'keep': 142,\n",
       " 'i\\x92m': 143,\n",
       " 'corona': 144,\n",
       " 'good': 145,\n",
       " 'items': 146,\n",
       " 'after': 147,\n",
       " 'panicbuying': 148,\n",
       " 'into': 149,\n",
       " 'why': 150,\n",
       " 'health': 151,\n",
       " 'most': 152,\n",
       " 'shop': 153,\n",
       " 'also': 154,\n",
       " '3': 155,\n",
       " 'stop': 156,\n",
       " \"i'm\": 157,\n",
       " 'every': 158,\n",
       " 'weeks': 159,\n",
       " 'while': 160,\n",
       " 'delivery': 161,\n",
       " 'right': 162,\n",
       " 'new': 163,\n",
       " 's': 164,\n",
       " 'had': 165,\n",
       " 'market': 166,\n",
       " 'week': 167,\n",
       " 'working': 168,\n",
       " 'last': 169,\n",
       " 'am': 170,\n",
       " 'sick': 171,\n",
       " 'way': 172,\n",
       " 'may': 173,\n",
       " 'leave': 174,\n",
       " 'days': 175,\n",
       " 'were': 176,\n",
       " 'doing': 177,\n",
       " 'really': 178,\n",
       " 'long': 179,\n",
       " 'much': 180,\n",
       " 'free': 181,\n",
       " 'off': 182,\n",
       " 'got': 183,\n",
       " 'want': 184,\n",
       " 'sanitizer': 185,\n",
       " 'well': 186,\n",
       " 'things': 187,\n",
       " 'world': 188,\n",
       " 'safe': 189,\n",
       " 'oil': 190,\n",
       " 'elderly': 191,\n",
       " 'etc': 192,\n",
       " 'few': 193,\n",
       " 'then': 194,\n",
       " 'getting': 195,\n",
       " 'could': 196,\n",
       " 'line': 197,\n",
       " 'supermarkets': 198,\n",
       " 'spread': 199,\n",
       " 'use': 200,\n",
       " 'everything': 201,\n",
       " 'supply': 202,\n",
       " 'before': 203,\n",
       " 'workers': 204,\n",
       " 'can\\x92t': 205,\n",
       " 'customers': 206,\n",
       " 'its': 207,\n",
       " 'enough': 208,\n",
       " 'where': 209,\n",
       " 'pasta': 210,\n",
       " 'back': 211,\n",
       " 'first': 212,\n",
       " 'money': 213,\n",
       " 'employees': 214,\n",
       " 'business': 215,\n",
       " 'amazon': 216,\n",
       " 'open': 217,\n",
       " 'crisis': 218,\n",
       " 'call': 219,\n",
       " 'products': 220,\n",
       " 'said': 221,\n",
       " 'around': 222,\n",
       " 'too': 223,\n",
       " 'lockdown': 224,\n",
       " 'outbreak': 225,\n",
       " 'high': 226,\n",
       " 'public': 227,\n",
       " 'hoarding': 228,\n",
       " 'seen': 229,\n",
       " 'next': 230,\n",
       " 'two': 231,\n",
       " 'government': 232,\n",
       " 'self': 233,\n",
       " 'same': 234,\n",
       " 'groceries': 235,\n",
       " 'never': 236,\n",
       " '5': 237,\n",
       " 'he': 238,\n",
       " 'hours': 239,\n",
       " 'masks': 240,\n",
       " 'social': 241,\n",
       " 'thing': 242,\n",
       " 'sure': 243,\n",
       " 'family': 244,\n",
       " 'paid': 245,\n",
       " 'very': 246,\n",
       " 'times': 247,\n",
       " 'come': 248,\n",
       " 'roll': 249,\n",
       " 'full': 250,\n",
       " 'months': 251,\n",
       " \"can't\": 252,\n",
       " 'care': 253,\n",
       " 'lot': 254,\n",
       " 'someone': 255,\n",
       " 'via': 256,\n",
       " 'price': 257,\n",
       " 'schools': 258,\n",
       " 'did': 259,\n",
       " 'anyone': 260,\n",
       " 'low': 261,\n",
       " 'live': 262,\n",
       " 'quarantine': 263,\n",
       " '4': 264,\n",
       " 'let': 265,\n",
       " 'hands': 266,\n",
       " 'extra': 267,\n",
       " 'goods': 268,\n",
       " 'others': 269,\n",
       " 'thank': 270,\n",
       " 'tp': 271,\n",
       " 'find': 272,\n",
       " 'check': 273,\n",
       " 'coronavirusupdate': 274,\n",
       " 'since': 275,\n",
       " 'through': 276,\n",
       " 'avoid': 277,\n",
       " 'big': 278,\n",
       " 'crazy': 279,\n",
       " 'coronavirusoutbreak': 280,\n",
       " 'say': 281,\n",
       " 'look': 282,\n",
       " 'having': 283,\n",
       " 'pay': 284,\n",
       " 'needs': 285,\n",
       " 'remember': 286,\n",
       " 'left': 287,\n",
       " 'bought': 288,\n",
       " 'news': 289,\n",
       " 'already': 290,\n",
       " 'canned': 291,\n",
       " 'close': 292,\n",
       " 'without': 293,\n",
       " 'available': 294,\n",
       " 'stuff': 295,\n",
       " 'taking': 296,\n",
       " 'support': 297,\n",
       " 'u': 298,\n",
       " 'thought': 299,\n",
       " 'bank': 300,\n",
       " 'case': 301,\n",
       " 'which': 302,\n",
       " 'able': 303,\n",
       " 'end': 304,\n",
       " 'ppl': 305,\n",
       " 'until': 306,\n",
       " 'companies': 307,\n",
       " 'staff': 308,\n",
       " 'situation': 309,\n",
       " 'she': 310,\n",
       " 'closed': 311,\n",
       " 'cleaning': 312,\n",
       " 'made': 313,\n",
       " 'stocking': 314,\n",
       " 'amid': 315,\n",
       " 'toiletpaper': 316,\n",
       " 'soap': 317,\n",
       " 'order': 318,\n",
       " 'great': 319,\n",
       " 'country': 320,\n",
       " 'gone': 321,\n",
       " 'each': 322,\n",
       " 'best': 323,\n",
       " 'fear': 324,\n",
       " 'coming': 325,\n",
       " 'banks': 326,\n",
       " 'folks': 327,\n",
       " 'china': 328,\n",
       " 'school': 329,\n",
       " 'businesses': 330,\n",
       " 'life': 331,\n",
       " 'gas': 332,\n",
       " 'trying': 333,\n",
       " 'run': 334,\n",
       " 'wash': 335,\n",
       " 'eat': 336,\n",
       " 'services': 337,\n",
       " 'else': 338,\n",
       " 'you\\x92re': 339,\n",
       " 'donate': 340,\n",
       " '6': 341,\n",
       " 'travel': 342,\n",
       " 'something': 343,\n",
       " 'risk': 344,\n",
       " 'making': 345,\n",
       " 'worried': 346,\n",
       " 'trump': 347,\n",
       " 'gonna': 348,\n",
       " 'does': 349,\n",
       " 'small': 350,\n",
       " 'her': 351,\n",
       " 'non': 352,\n",
       " 'global': 353,\n",
       " 'w': 354,\n",
       " 're': 355,\n",
       " 'walmart': 356,\n",
       " 'month': 357,\n",
       " 'important': 358,\n",
       " 'economy': 359,\n",
       " 'maybe': 360,\n",
       " 'march': 361,\n",
       " \"there's\": 362,\n",
       " 'normal': 363,\n",
       " 'coronavirus\\r\\r': 364,\n",
       " 'impact': 365,\n",
       " 'his': 366,\n",
       " 'emergency': 367,\n",
       " 'place': 368,\n",
       " 'cases': 369,\n",
       " 'selling': 370,\n",
       " 'face': 371,\n",
       " 'put': 372,\n",
       " 'sanitizers': 373,\n",
       " 'media': 374,\n",
       " 'uk': 375,\n",
       " 'testing': 376,\n",
       " 'retailers': 377,\n",
       " 'away': 378,\n",
       " 'start': 379,\n",
       " 'running': 380,\n",
       " 'give': 381,\n",
       " 'hard': 382,\n",
       " 'yet': 383,\n",
       " 'nothing': 384,\n",
       " 'morning': 385,\n",
       " 'hit': 386,\n",
       " 'better': 387,\n",
       " 'contact': 388,\n",
       " 'yesterday': 389,\n",
       " 'afford': 390,\n",
       " 'essentials': 391,\n",
       " 'lines': 392,\n",
       " 'shoppers': 393,\n",
       " 'hope': 394,\n",
       " 'less': 395,\n",
       " 'increase': 396,\n",
       " '19\\r\\r': 397,\n",
       " 'stocked': 398,\n",
       " 'person': 399,\n",
       " 'share': 400,\n",
       " 'says': 401,\n",
       " \"you're\": 402,\n",
       " 'calm': 403,\n",
       " 'saw': 404,\n",
       " 'consider': 405,\n",
       " 'italy': 406,\n",
       " 'old': 407,\n",
       " 'rice': 408,\n",
       " 'ever': 409,\n",
       " 'vulnerable': 410,\n",
       " 'closing': 411,\n",
       " 'least': 412,\n",
       " 'house': 413,\n",
       " 'instead': 414,\n",
       " 'such': 415,\n",
       " 'little': 416,\n",
       " 'must': 417,\n",
       " 'done': 418,\n",
       " 'outside': 419,\n",
       " 'list': 420,\n",
       " 'markets': 421,\n",
       " 'state': 422,\n",
       " 'coronavirusupdates': 423,\n",
       " 'americans': 424,\n",
       " 'almost': 425,\n",
       " 'together': 426,\n",
       " 'anything': 427,\n",
       " 'thanks': 428,\n",
       " 'we\\x92re': 429,\n",
       " 'might': 430,\n",
       " 'across': 431,\n",
       " 'shit': 432,\n",
       " 'shops': 433,\n",
       " 'night': 434,\n",
       " 'against': 435,\n",
       " 'i\\x92ve': 436,\n",
       " 'read': 437,\n",
       " 'piling': 438,\n",
       " 'wipes': 439,\n",
       " 'healthy': 440,\n",
       " 'apple': 441,\n",
       " 'large': 442,\n",
       " '10': 443,\n",
       " 'community': 444,\n",
       " 'real': 445,\n",
       " 'try': 446,\n",
       " 'city': 447,\n",
       " 'milk': 448,\n",
       " 'safety': 449,\n",
       " 'part': 450,\n",
       " 'year': 451,\n",
       " 'lots': 452,\n",
       " 'shut': 453,\n",
       " \"i've\": 454,\n",
       " 'beans': 455,\n",
       " 'bad': 456,\n",
       " 'kind': 457,\n",
       " 'protect': 458,\n",
       " 'forget': 459,\n",
       " 'won\\x92t': 460,\n",
       " 'realdonaldtrump': 461,\n",
       " 'shortage': 462,\n",
       " 'families': 463,\n",
       " 'probably': 464,\n",
       " 'another': 465,\n",
       " 'clean': 466,\n",
       " \"won't\": 467,\n",
       " 'sales': 468,\n",
       " 'pick': 469,\n",
       " 'understand': 470,\n",
       " 'ask': 471,\n",
       " 'continue': 472,\n",
       " 'places': 473,\n",
       " 'job': 474,\n",
       " 'area': 475,\n",
       " 'chain': 476,\n",
       " 'shortages': 477,\n",
       " '7': 478,\n",
       " 'essential': 479,\n",
       " 'foods': 480,\n",
       " 'again': 481,\n",
       " 'basic': 482,\n",
       " 'cause': 483,\n",
       " 'possible': 484,\n",
       " 'change': 485,\n",
       " 'feel': 486,\n",
       " 'bread': 487,\n",
       " 'hour': 488,\n",
       " 'sold': 489,\n",
       " 'costco': 490,\n",
       " 'increased': 491,\n",
       " 'starting': 492,\n",
       " '2020': 493,\n",
       " 'told': 494,\n",
       " 'worth': 495,\n",
       " 'update': 496,\n",
       " 'especially': 497,\n",
       " 'actually': 498,\n",
       " 'don': 499,\n",
       " 'canada': 500,\n",
       " 'medical': 501,\n",
       " 'sell': 502,\n",
       " 'stockpiling': 503,\n",
       " 'fight': 504,\n",
       " 'report': 505,\n",
       " 'protection': 506,\n",
       " 'far': 507,\n",
       " 'drop': 508,\n",
       " 'under': 509,\n",
       " 'cat': 510,\n",
       " 'panicking': 511,\n",
       " 'tell': 512,\n",
       " 'seeing': 513,\n",
       " 'man': 514,\n",
       " 'apocalypse': 515,\n",
       " 'healthcare': 516,\n",
       " 'regular': 517,\n",
       " 'looking': 518,\n",
       " 'based': 519,\n",
       " 'aisle': 520,\n",
       " 'gt': 521,\n",
       " 'years': 522,\n",
       " 'seriously': 523,\n",
       " 'hey': 524,\n",
       " 'friends': 525,\n",
       " 'purchase': 526,\n",
       " '\\x94': 527,\n",
       " 'frozen': 528,\n",
       " 'pharmacy': 529,\n",
       " 'response': 530,\n",
       " 'c': 531,\n",
       " 'flu': 532,\n",
       " 'dog': 533,\n",
       " 'tonight': 534,\n",
       " 'front': 535,\n",
       " 'meat': 536,\n",
       " 'early': 537,\n",
       " 'restaurants': 538,\n",
       " 'watch': 539,\n",
       " 'control': 540,\n",
       " 'y\\x92all': 541,\n",
       " 'necessary': 542,\n",
       " 'service': 543,\n",
       " '30': 544,\n",
       " 'mask': 545,\n",
       " 'couple': 546,\n",
       " 'dont': 547,\n",
       " 'target': 548,\n",
       " 'die': 549,\n",
       " 'current': 550,\n",
       " 'tomorrow': 551,\n",
       " 'including': 552,\n",
       " 'ago': 553,\n",
       " \"we're\": 554,\n",
       " 'wait': 555,\n",
       " 'prevent': 556,\n",
       " 'remain': 557,\n",
       " 'concerns': 558,\n",
       " 'industry': 559,\n",
       " 'bit': 560,\n",
       " 'stocks': 561,\n",
       " 'whole': 562,\n",
       " 'means': 563,\n",
       " 'insurance': 564,\n",
       " 'tested': 565,\n",
       " 'personal': 566,\n",
       " 'they\\x92re': 567,\n",
       " 'major': 568,\n",
       " 'disease': 569,\n",
       " 'isolation': 570,\n",
       " 'cancelled': 571,\n",
       " '14': 572,\n",
       " 'ok': 573,\n",
       " 'struggling': 574,\n",
       " '20': 575,\n",
       " 'advice': 576,\n",
       " 'system': 577,\n",
       " 'distancing': 578,\n",
       " 'needed': 579,\n",
       " 'mass': 580,\n",
       " 'cannot': 581,\n",
       " 'hoard': 582,\n",
       " 'packed': 583,\n",
       " 'kids': 584,\n",
       " 'love': 585,\n",
       " 'hysteria': 586,\n",
       " 'baby': 587,\n",
       " '100': 588,\n",
       " 'alcohol': 589,\n",
       " 'hygiene': 590,\n",
       " \"that's\": 591,\n",
       " 'soon': 592,\n",
       " 'waiting': 593,\n",
       " 'isn\\x92t': 594,\n",
       " 'cash': 595,\n",
       " 'ready': 596,\n",
       " 'older': 597,\n",
       " 'scared': 598,\n",
       " 'looks': 599,\n",
       " 'e': 600,\n",
       " 'found': 601,\n",
       " 'helping': 602,\n",
       " 'stoppanicbuying': 603,\n",
       " 'video': 604,\n",
       " 'usual': 605,\n",
       " 'effect': 606,\n",
       " 'rolls': 607,\n",
       " 'fears': 608,\n",
       " 'medicine': 609,\n",
       " 'pantry': 610,\n",
       " 'events': 611,\n",
       " 'temporarily': 612,\n",
       " 'using': 613,\n",
       " 'there\\x92s': 614,\n",
       " 'economic': 615,\n",
       " 'chaos': 616,\n",
       " 'point': 617,\n",
       " 'fast': 618,\n",
       " 'selfish': 619,\n",
       " 'seems': 620,\n",
       " '12': 621,\n",
       " 'shipping': 622,\n",
       " 'worse': 623,\n",
       " 'staying': 624,\n",
       " 'm': 625,\n",
       " 'coronapocolypse': 626,\n",
       " 'save': 627,\n",
       " 'email': 628,\n",
       " 'goes': 629,\n",
       " 'income': 630,\n",
       " 'wanted': 631,\n",
       " 'guys': 632,\n",
       " 'ass': 633,\n",
       " 'consumers': 634,\n",
       " 'happen': 635,\n",
       " '000': 636,\n",
       " 'panicked': 637,\n",
       " 'always': 638,\n",
       " 'saying': 639,\n",
       " 'everybody': 640,\n",
       " 'kill': 641,\n",
       " 'limit': 642,\n",
       " 'weekend': 643,\n",
       " 'prepare': 644,\n",
       " 'america': 645,\n",
       " 'half': 646,\n",
       " 'nice': 647,\n",
       " 'pass': 648,\n",
       " 'friday': 649,\n",
       " 'cost': 650,\n",
       " 'visit': 651,\n",
       " \"let's\": 652,\n",
       " 'ahead': 653,\n",
       " 'thinking': 654,\n",
       " 'office': 655,\n",
       " 'gov': 656,\n",
       " 'advantage': 657,\n",
       " 'gatherings': 658,\n",
       " 'quarantined': 659,\n",
       " 'expect': 660,\n",
       " 'affected': 661,\n",
       " 'b': 662,\n",
       " 'likely': 663,\n",
       " 'crowds': 664,\n",
       " 'idea': 665,\n",
       " 'tesco': 666,\n",
       " 'eating': 667,\n",
       " 'positive': 668,\n",
       " 'ones': 669,\n",
       " 'confirmed': 670,\n",
       " 'fuck': 671,\n",
       " 'called': 672,\n",
       " 'chains': 673,\n",
       " 'usa': 674,\n",
       " 'unemployment': 675,\n",
       " 'clear': 676,\n",
       " 'crowded': 677,\n",
       " 'provide': 678,\n",
       " 'restaurant': 679,\n",
       " 'drive': 680,\n",
       " 'sense': 681,\n",
       " 'president': 682,\n",
       " 'children': 683,\n",
       " 'access': 684,\n",
       " 'either': 685,\n",
       " 'ur': 686,\n",
       " 'cut': 687,\n",
       " 'post': 688,\n",
       " '\\x94\\r\\r': 689,\n",
       " 'fact': 690,\n",
       " 'friend': 691,\n",
       " 'necessities': 692,\n",
       " 'started': 693,\n",
       " 'trip': 694,\n",
       " 'test': 695,\n",
       " 'didn\\x92t': 696,\n",
       " \"i'll\": 697,\n",
       " 'plenty': 698,\n",
       " 'entire': 699,\n",
       " 'heard': 700,\n",
       " \"they're\": 701,\n",
       " 'toiletpaperapocalypse': 702,\n",
       " 'though': 703,\n",
       " 'pets': 704,\n",
       " 'company': 705,\n",
       " 'gets': 706,\n",
       " 'announced': 707,\n",
       " 'living': 708,\n",
       " 'mind': 709,\n",
       " 'deal': 710,\n",
       " 'coronavirususa': 711,\n",
       " 'wrong': 712,\n",
       " 'tips': 713,\n",
       " 'per': 714,\n",
       " 'currently': 715,\n",
       " 'tv': 716,\n",
       " \"isn't\": 717,\n",
       " 'perishable': 718,\n",
       " 'website': 719,\n",
       " 'meals': 720,\n",
       " 'lives': 721,\n",
       " \"what's\": 722,\n",
       " 'related': 723,\n",
       " 'except': 724,\n",
       " 'rather': 725,\n",
       " 'reason': 726,\n",
       " 'bare': 727,\n",
       " 'side': 728,\n",
       " 'daily': 729,\n",
       " 'guess': 730,\n",
       " 'break': 731,\n",
       " 'bulk': 732,\n",
       " 'information': 733,\n",
       " 'despite': 734,\n",
       " 'yes': 735,\n",
       " 'card': 736,\n",
       " 'bill': 737,\n",
       " 'yourself': 738,\n",
       " 'info': 739,\n",
       " 'behind': 740,\n",
       " 'busy': 741,\n",
       " 'product': 742,\n",
       " 'shows': 743,\n",
       " 'become': 744,\n",
       " 'meanwhile': 745,\n",
       " 'comes': 746,\n",
       " 'lost': 747,\n",
       " 'gouging': 748,\n",
       " '800': 749,\n",
       " 'mean': 750,\n",
       " 'worst': 751,\n",
       " 'meet': 752,\n",
       " 'hell': 753,\n",
       " '50': 754,\n",
       " 'problem': 755,\n",
       " 'reports': 756,\n",
       " 'jobs': 757,\n",
       " 'data': 758,\n",
       " 'asked': 759,\n",
       " 'pretty': 760,\n",
       " 'oh': 761,\n",
       " 'cart': 762,\n",
       " 'security': 763,\n",
       " 'sainsburys': 764,\n",
       " 'telling': 765,\n",
       " 'moment': 766,\n",
       " 'prepared': 767,\n",
       " 'between': 768,\n",
       " 'ridiculous': 769,\n",
       " 'concerned': 770,\n",
       " 'imagine': 771,\n",
       " 'socialdistancing': 772,\n",
       " 'stupid': 773,\n",
       " 'later': 774,\n",
       " 'door': 775,\n",
       " 'd': 776,\n",
       " 'makes': 777,\n",
       " 'inside': 778,\n",
       " '\\x95': 779,\n",
       " 'allowed': 780,\n",
       " 'light': 781,\n",
       " 'communities': 782,\n",
       " 'deliver': 783,\n",
       " 'pharmacies': 784,\n",
       " 'measures': 785,\n",
       " 'panicshopping': 786,\n",
       " 'tip': 787,\n",
       " 'govt': 788,\n",
       " 'closures': 789,\n",
       " 'plan': 790,\n",
       " 'chinese': 791,\n",
       " 'continues': 792,\n",
       " 'lower': 793,\n",
       " 'ecommerce': 794,\n",
       " 'poor': 795,\n",
       " 'infected': 796,\n",
       " 'once': 797,\n",
       " 'national': 798,\n",
       " 'follow': 799,\n",
       " 'fresh': 800,\n",
       " 'stockpile': 801,\n",
       " 'donations': 802,\n",
       " 'customer': 803,\n",
       " \"didn't\": 804,\n",
       " 'gloves': 805,\n",
       " 'bottled': 806,\n",
       " 'i\\x92ll': 807,\n",
       " 'own': 808,\n",
       " 'literally': 809,\n",
       " 'countries': 810,\n",
       " 'kroger': 811,\n",
       " 'god': 812,\n",
       " 'wine': 813,\n",
       " 'shelf': 814,\n",
       " 'section': 815,\n",
       " 'plans': 816,\n",
       " 'facing': 817,\n",
       " 'sent': 818,\n",
       " '19uk': 819,\n",
       " 'shame': 820,\n",
       " 'stopped': 821,\n",
       " 'credit': 822,\n",
       " 'phone': 823,\n",
       " 'bring': 824,\n",
       " 'american': 825,\n",
       " \"we've\": 826,\n",
       " 'tax': 827,\n",
       " 'donating': 828,\n",
       " 'household': 829,\n",
       " \"here's\": 830,\n",
       " 'covid19canada': 831,\n",
       " 'coughing': 832,\n",
       " 'feed': 833,\n",
       " 'meds': 834,\n",
       " '15': 835,\n",
       " 'toiletpapercrisis': 836,\n",
       " 'lysol': 837,\n",
       " 'higher': 838,\n",
       " 'anxiety': 839,\n",
       " 'chicken': 840,\n",
       " 'number': 841,\n",
       " 'group': 842,\n",
       " 'food\\r\\r': 843,\n",
       " 'longer': 844,\n",
       " 'parents': 845,\n",
       " 'issues': 846,\n",
       " 'that\\x92s': 847,\n",
       " 'stuck': 848,\n",
       " 'insane': 849,\n",
       " 'california': 850,\n",
       " 'let\\x92s': 851,\n",
       " 'myself': 852,\n",
       " 'experience': 853,\n",
       " 'ability': 854,\n",
       " 'distance': 855,\n",
       " 'resources': 856,\n",
       " 'carts': 857,\n",
       " 'april': 858,\n",
       " 'further': 859,\n",
       " 'pet': 860,\n",
       " 'worry': 861,\n",
       " 'leave\\r\\r': 862,\n",
       " 'cdc': 863,\n",
       " 'everywhere': 864,\n",
       " 'cheap': 865,\n",
       " 'taken': 866,\n",
       " 'wish': 867,\n",
       " 'issue': 868,\n",
       " 'spend': 869,\n",
       " 'show': 870,\n",
       " 'touch': 871,\n",
       " 'precautions': 872,\n",
       " 'spreads': 873,\n",
       " 'debt': 874,\n",
       " 'monday': 875,\n",
       " 'behavior': 876,\n",
       " 'ensure': 877,\n",
       " 'brand': 878,\n",
       " 'talk': 879,\n",
       " 'rush': 880,\n",
       " 'term': 881,\n",
       " 'saturday': 882,\n",
       " 'chance': 883,\n",
       " 'several': 884,\n",
       " 'ill': 885,\n",
       " 'queue': 886,\n",
       " 'financial': 887,\n",
       " 'employee': 888,\n",
       " '8': 889,\n",
       " 'single': 890,\n",
       " 'kits': 891,\n",
       " 'thousands': 892,\n",
       " 'amount': 893,\n",
       " 'evening': 894,\n",
       " 'bekind': 895,\n",
       " 'rise': 896,\n",
       " 'happy': 897,\n",
       " 'offer': 898,\n",
       " 'car': 899,\n",
       " 'wonder': 900,\n",
       " 'survive': 901,\n",
       " 'huge': 902,\n",
       " 'eggs': 903,\n",
       " 'set': 904,\n",
       " 'stress': 905,\n",
       " 'common': 906,\n",
       " 'leaving': 907,\n",
       " 'tests': 908,\n",
       " 'loo': 909,\n",
       " 'usually': 910,\n",
       " 'pack': 911,\n",
       " 'below': 912,\n",
       " 'weekly': 913,\n",
       " 'losing': 914,\n",
       " 'offers': 915,\n",
       " 'ticket': 916,\n",
       " 'breaking': 917,\n",
       " 'top': 918,\n",
       " 'traffic': 919,\n",
       " 'learn': 920,\n",
       " 'coronaviruscanada': 921,\n",
       " 'boost': 922,\n",
       " 'both': 923,\n",
       " 'woman': 924,\n",
       " 'diet': 925,\n",
       " 'interesting': 926,\n",
       " 'notice': 927,\n",
       " 'habits': 928,\n",
       " 'takes': 929,\n",
       " 'question': 930,\n",
       " 'gift': 931,\n",
       " 'tissue': 932,\n",
       " 'different': 933,\n",
       " 'causing': 934,\n",
       " 'afternoon': 935,\n",
       " 'nobody': 936,\n",
       " 'rest': 937,\n",
       " 'him': 938,\n",
       " '\\x96': 939,\n",
       " 'fighting': 940,\n",
       " 'past': 941,\n",
       " 'towels': 942,\n",
       " 'assistance': 943,\n",
       " 'dear': 944,\n",
       " 'putting': 945,\n",
       " 'neighbors': 946,\n",
       " 'madness': 947,\n",
       " 'lol': 948,\n",
       " 'limited': 949,\n",
       " 'mad': 950,\n",
       " 'orders': 951,\n",
       " 'happening': 952,\n",
       " 'offering': 953,\n",
       " 'aisles': 954,\n",
       " 'human': 955,\n",
       " 'story': 956,\n",
       " 'add': 957,\n",
       " 'direct': 958,\n",
       " 'worker': 959,\n",
       " 'purchases': 960,\n",
       " 'head': 961,\n",
       " 'forced': 962,\n",
       " 'delivered': 963,\n",
       " 'bog': 964,\n",
       " 'thread': 965,\n",
       " 'doesn\\x92t': 966,\n",
       " 'falling': 967,\n",
       " 'recession': 968,\n",
       " 'cure': 969,\n",
       " '\\x97': 970,\n",
       " 'foodbanks': 971,\n",
       " 'themselves': 972,\n",
       " 'residents': 973,\n",
       " 'value': 974,\n",
       " 'ceo': 975,\n",
       " 'rate': 976,\n",
       " 'profit': 977,\n",
       " 'pile': 978,\n",
       " 'spending': 979,\n",
       " \"doesn't\": 980,\n",
       " 'plus': 981,\n",
       " 'afraid': 982,\n",
       " 'fall': 983,\n",
       " 'fill': 984,\n",
       " 'immune': 985,\n",
       " 'looked': 986,\n",
       " 'play': 987,\n",
       " 'normally': 988,\n",
       " 'checkout': 989,\n",
       " 'brands': 990,\n",
       " 'preparing': 991,\n",
       " 'season': 992,\n",
       " 'relief': 993,\n",
       " 'finally': 994,\n",
       " 'asking': 995,\n",
       " 'according': 996,\n",
       " 'opening': 997,\n",
       " 'easy': 998,\n",
       " 'fucking': 999,\n",
       " 'act': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "allData = df.to_numpy()\n",
    "samples = allData[:,0]\n",
    "y = allData[:,1]\n",
    "maxLen = 20\n",
    "maxWords = 10000\n",
    "tok = Tokenizer(num_words = maxWords)\n",
    "tok.fit_on_texts(samples)\n",
    "sequences = tok.texts_to_sequences(samples)\n",
    "oneHot = tok.sequences_to_matrix(sequences, mode='binary')\n",
    "wordInd = tok.word_index\n",
    "wordInd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max padding that is need is:  65\n",
      "Thus the max length of the sequences is  65\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3798, 65)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#One hot get rids of time aspect of data \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "maxLen = max([len(sequence) for sequence in sequences])\n",
    "print(\"Max padding that is need is: \", maxLen)\n",
    "print(\"Thus the max length of the sequences is \", maxLen)\n",
    "x = pad_sequences(sequences, maxlen= maxLen)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y dictionary:  {'Extremely Negative': 0, 'Extremely Positive': 1, 'Negative': 2, 'Neutral': 3, 'Positive': 4}\n",
      "To integer categorical [0 4 1 ... 3 0 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "yDict = {}\n",
    "yDictRev = {}\n",
    "uniqueYs = np.unique(y)\n",
    "for i in range(len(uniqueYs)):\n",
    "    yDictRev[i] = uniqueYs[i]\n",
    "    yDict[uniqueYs[i]] = i\n",
    "print(\"y dictionary: \", yDict)      #As a hyposthesis a scale might make better features\n",
    "for i in range(len(y)):\n",
    "    y[i] = yDict[y[i]]\n",
    "print(\"To integer categorical\", y)\n",
    "from keras.utils import to_categorical\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotToCat(vector):\n",
    "    arg = np.argmax(vector)\n",
    "    return yDictRev[arg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.5550 - accuracy: 0.2680 - val_loss: 1.5476 - val_accuracy: 0.2605\n",
      "Epoch 2/100\n",
      "107/107 [==============================] - 0s 960us/step - loss: 1.4923 - accuracy: 0.3327 - val_loss: 1.5291 - val_accuracy: 0.2763\n",
      "Epoch 3/100\n",
      "107/107 [==============================] - 0s 964us/step - loss: 1.4537 - accuracy: 0.4032 - val_loss: 1.5221 - val_accuracy: 0.2500\n",
      "Epoch 4/100\n",
      "107/107 [==============================] - 0s 989us/step - loss: 1.4122 - accuracy: 0.4807 - val_loss: 1.5153 - val_accuracy: 0.2816\n",
      "Epoch 5/100\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.3599 - accuracy: 0.5190 - val_loss: 1.5090 - val_accuracy: 0.2789\n",
      "Epoch 6/100\n",
      "107/107 [==============================] - 0s 971us/step - loss: 1.2954 - accuracy: 0.5945 - val_loss: 1.5046 - val_accuracy: 0.2895\n",
      "Epoch 7/100\n",
      "107/107 [==============================] - 0s 986us/step - loss: 1.2219 - accuracy: 0.6431 - val_loss: 1.4931 - val_accuracy: 0.2921\n",
      "Epoch 8/100\n",
      "107/107 [==============================] - 0s 990us/step - loss: 1.1412 - accuracy: 0.6922 - val_loss: 1.4859 - val_accuracy: 0.3026\n",
      "Epoch 9/100\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.0571 - accuracy: 0.7270 - val_loss: 1.4781 - val_accuracy: 0.3184\n",
      "Epoch 10/100\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.9707 - accuracy: 0.7589 - val_loss: 1.4803 - val_accuracy: 0.3184\n",
      "Epoch 11/100\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.8870 - accuracy: 0.7838 - val_loss: 1.4748 - val_accuracy: 0.3289\n",
      "Epoch 12/100\n",
      "107/107 [==============================] - 0s 995us/step - loss: 0.8052 - accuracy: 0.8192 - val_loss: 1.4742 - val_accuracy: 0.3342\n",
      "Epoch 13/100\n",
      "107/107 [==============================] - 0s 984us/step - loss: 0.7273 - accuracy: 0.8479 - val_loss: 1.4831 - val_accuracy: 0.3447\n",
      "Epoch 14/100\n",
      "107/107 [==============================] - 0s 998us/step - loss: 0.6545 - accuracy: 0.8681 - val_loss: 1.4928 - val_accuracy: 0.3421\n",
      "Epoch 15/100\n",
      "107/107 [==============================] - 0s 975us/step - loss: 0.5868 - accuracy: 0.8909 - val_loss: 1.5026 - val_accuracy: 0.3474\n",
      "Epoch 16/100\n",
      "107/107 [==============================] - 0s 985us/step - loss: 0.5245 - accuracy: 0.9032 - val_loss: 1.5203 - val_accuracy: 0.3526\n",
      "Epoch 17/100\n",
      "107/107 [==============================] - 0s 954us/step - loss: 0.4669 - accuracy: 0.9198 - val_loss: 1.5351 - val_accuracy: 0.3632\n",
      "Epoch 18/100\n",
      "107/107 [==============================] - 0s 976us/step - loss: 0.4148 - accuracy: 0.9348 - val_loss: 1.5601 - val_accuracy: 0.3500\n",
      "Epoch 19/100\n",
      "107/107 [==============================] - 0s 977us/step - loss: 0.3671 - accuracy: 0.9456 - val_loss: 1.5790 - val_accuracy: 0.3500\n",
      "Epoch 20/100\n",
      "107/107 [==============================] - 0s 987us/step - loss: 0.3251 - accuracy: 0.9529 - val_loss: 1.5999 - val_accuracy: 0.3789\n",
      "Epoch 21/100\n",
      "107/107 [==============================] - 0s 950us/step - loss: 0.2862 - accuracy: 0.9623 - val_loss: 1.6258 - val_accuracy: 0.3684\n",
      "Epoch 22/100\n",
      "107/107 [==============================] - 0s 965us/step - loss: 0.2516 - accuracy: 0.9693 - val_loss: 1.6553 - val_accuracy: 0.3658\n",
      "Epoch 23/100\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.2214 - accuracy: 0.9719 - val_loss: 1.6825 - val_accuracy: 0.3632\n",
      "Epoch 24/100\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.1942 - accuracy: 0.9778 - val_loss: 1.7141 - val_accuracy: 0.3632\n",
      "Epoch 25/100\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.1703 - accuracy: 0.9798 - val_loss: 1.7460 - val_accuracy: 0.3579\n",
      "Epoch 26/100\n",
      "107/107 [==============================] - 0s 959us/step - loss: 0.1487 - accuracy: 0.9827 - val_loss: 1.7769 - val_accuracy: 0.3658\n",
      "Epoch 27/100\n",
      "107/107 [==============================] - 0s 976us/step - loss: 0.1298 - accuracy: 0.9854 - val_loss: 1.8062 - val_accuracy: 0.3632\n",
      "Epoch 28/100\n",
      "107/107 [==============================] - 0s 966us/step - loss: 0.1134 - accuracy: 0.9895 - val_loss: 1.8496 - val_accuracy: 0.3579\n",
      "Epoch 29/100\n",
      "107/107 [==============================] - 0s 997us/step - loss: 0.0982 - accuracy: 0.9906 - val_loss: 1.8838 - val_accuracy: 0.3605\n",
      "Epoch 30/100\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.0858 - accuracy: 0.9906 - val_loss: 1.9300 - val_accuracy: 0.3421\n",
      "Epoch 31/100\n",
      "107/107 [==============================] - 0s 970us/step - loss: 0.0747 - accuracy: 0.9927 - val_loss: 1.9650 - val_accuracy: 0.3263\n",
      "Epoch 32/100\n",
      "107/107 [==============================] - 0s 988us/step - loss: 0.0649 - accuracy: 0.9939 - val_loss: 2.0074 - val_accuracy: 0.3289\n",
      "Epoch 33/100\n",
      "107/107 [==============================] - 0s 972us/step - loss: 0.0560 - accuracy: 0.9944 - val_loss: 2.0588 - val_accuracy: 0.3289\n",
      "Epoch 34/100\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.0488 - accuracy: 0.9956 - val_loss: 2.0945 - val_accuracy: 0.3211\n",
      "Epoch 35/100\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.0423 - accuracy: 0.9959 - val_loss: 2.1432 - val_accuracy: 0.3211\n",
      "Epoch 36/100\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.0368 - accuracy: 0.9962 - val_loss: 2.1903 - val_accuracy: 0.3184\n",
      "Epoch 37/100\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.0319 - accuracy: 0.9956 - val_loss: 2.2423 - val_accuracy: 0.3316\n",
      "Epoch 38/100\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.0275 - accuracy: 0.9974 - val_loss: 2.2982 - val_accuracy: 0.3263\n",
      "Epoch 39/100\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.0237 - accuracy: 0.9982 - val_loss: 2.3410 - val_accuracy: 0.3263\n",
      "Epoch 40/100\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.0206 - accuracy: 0.9985 - val_loss: 2.4055 - val_accuracy: 0.3289\n",
      "Epoch 41/100\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.0180 - accuracy: 0.9985 - val_loss: 2.4523 - val_accuracy: 0.3237\n",
      "Epoch 42/100\n",
      "107/107 [==============================] - 0s 954us/step - loss: 0.0156 - accuracy: 0.9985 - val_loss: 2.5126 - val_accuracy: 0.3263\n",
      "Epoch 43/100\n",
      "107/107 [==============================] - 0s 962us/step - loss: 0.0136 - accuracy: 0.9988 - val_loss: 2.5680 - val_accuracy: 0.3316\n",
      "Epoch 44/100\n",
      "107/107 [==============================] - 0s 968us/step - loss: 0.0117 - accuracy: 0.9988 - val_loss: 2.6208 - val_accuracy: 0.3316\n",
      "Epoch 45/100\n",
      "107/107 [==============================] - 0s 936us/step - loss: 0.0104 - accuracy: 0.9988 - val_loss: 2.6867 - val_accuracy: 0.3263\n",
      "Epoch 46/100\n",
      "107/107 [==============================] - 0s 974us/step - loss: 0.0090 - accuracy: 0.9991 - val_loss: 2.7417 - val_accuracy: 0.3316\n",
      "Epoch 47/100\n",
      "107/107 [==============================] - 0s 946us/step - loss: 0.0079 - accuracy: 0.9991 - val_loss: 2.8011 - val_accuracy: 0.3263\n",
      "Epoch 48/100\n",
      "107/107 [==============================] - 0s 939us/step - loss: 0.0069 - accuracy: 0.9991 - val_loss: 2.8687 - val_accuracy: 0.3263\n",
      "Epoch 49/100\n",
      "107/107 [==============================] - 0s 962us/step - loss: 0.0062 - accuracy: 0.9991 - val_loss: 2.9179 - val_accuracy: 0.3237\n",
      "Epoch 50/100\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 2.9726 - val_accuracy: 0.3263\n",
      "Epoch 51/100\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 3.0471 - val_accuracy: 0.3184\n",
      "Epoch 52/100\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 3.1113 - val_accuracy: 0.3237\n",
      "Epoch 53/100\n",
      "107/107 [==============================] - 0s 997us/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 3.1596 - val_accuracy: 0.3211\n",
      "Epoch 54/100\n",
      "107/107 [==============================] - 0s 986us/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 3.2151 - val_accuracy: 0.3237\n",
      "Epoch 55/100\n",
      "107/107 [==============================] - 0s 982us/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 3.2811 - val_accuracy: 0.3263\n",
      "Epoch 56/100\n",
      "107/107 [==============================] - 0s 935us/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 3.3320 - val_accuracy: 0.3158\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 0s 971us/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 3.4042 - val_accuracy: 0.3237\n",
      "Epoch 58/100\n",
      "107/107 [==============================] - 0s 960us/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 3.4653 - val_accuracy: 0.3289\n",
      "Epoch 59/100\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 3.5342 - val_accuracy: 0.3316\n",
      "Epoch 60/100\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 3.5767 - val_accuracy: 0.3237\n",
      "Epoch 61/100\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 3.6660 - val_accuracy: 0.3316\n",
      "Epoch 62/100\n",
      "107/107 [==============================] - 0s 975us/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 3.7072 - val_accuracy: 0.3263\n",
      "Epoch 63/100\n",
      "107/107 [==============================] - 0s 970us/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 3.7623 - val_accuracy: 0.3211\n",
      "Epoch 64/100\n",
      "107/107 [==============================] - 0s 978us/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 3.8307 - val_accuracy: 0.3237\n",
      "Epoch 65/100\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 3.8866 - val_accuracy: 0.3237\n",
      "Epoch 66/100\n",
      "107/107 [==============================] - 0s 993us/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 3.9498 - val_accuracy: 0.3237\n",
      "Epoch 67/100\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 4.0106 - val_accuracy: 0.3211\n",
      "Epoch 68/100\n",
      "107/107 [==============================] - 0s 997us/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 4.0649 - val_accuracy: 0.3237\n",
      "Epoch 69/100\n",
      "107/107 [==============================] - 0s 970us/step - loss: 8.8946e-04 - accuracy: 0.9997 - val_loss: 4.1277 - val_accuracy: 0.3211\n",
      "Epoch 70/100\n",
      "107/107 [==============================] - 0s 970us/step - loss: 7.5284e-04 - accuracy: 0.9997 - val_loss: 4.1946 - val_accuracy: 0.3263\n",
      "Epoch 71/100\n",
      "107/107 [==============================] - 0s 963us/step - loss: 8.4999e-04 - accuracy: 0.9994 - val_loss: 4.2408 - val_accuracy: 0.3263\n",
      "Epoch 72/100\n",
      "107/107 [==============================] - 0s 970us/step - loss: 9.3272e-04 - accuracy: 0.9994 - val_loss: 4.2958 - val_accuracy: 0.3289\n",
      "Epoch 73/100\n",
      "107/107 [==============================] - 0s 947us/step - loss: 6.0987e-04 - accuracy: 0.9997 - val_loss: 4.3581 - val_accuracy: 0.3263\n",
      "Epoch 74/100\n",
      "107/107 [==============================] - 0s 965us/step - loss: 7.3476e-04 - accuracy: 0.9994 - val_loss: 4.4026 - val_accuracy: 0.3237\n",
      "Epoch 75/100\n",
      "107/107 [==============================] - 0s 988us/step - loss: 5.2145e-04 - accuracy: 1.0000 - val_loss: 4.4577 - val_accuracy: 0.3237\n",
      "Epoch 76/100\n",
      "107/107 [==============================] - 0s 967us/step - loss: 5.4885e-04 - accuracy: 0.9997 - val_loss: 4.5037 - val_accuracy: 0.3211\n",
      "Epoch 77/100\n",
      "107/107 [==============================] - 0s 910us/step - loss: 4.4991e-04 - accuracy: 1.0000 - val_loss: 4.5686 - val_accuracy: 0.3316\n",
      "Epoch 78/100\n",
      "107/107 [==============================] - 0s 984us/step - loss: 6.2482e-04 - accuracy: 0.9994 - val_loss: 4.6036 - val_accuracy: 0.3211\n",
      "Epoch 79/100\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 4.1526e-04 - accuracy: 1.0000 - val_loss: 4.6660 - val_accuracy: 0.3263\n",
      "Epoch 80/100\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 4.3755e-04 - accuracy: 1.0000 - val_loss: 4.7168 - val_accuracy: 0.3184\n",
      "Epoch 81/100\n",
      "107/107 [==============================] - 0s 979us/step - loss: 4.8365e-04 - accuracy: 0.9997 - val_loss: 4.7604 - val_accuracy: 0.3184\n",
      "Epoch 82/100\n",
      "107/107 [==============================] - 0s 954us/step - loss: 3.6167e-04 - accuracy: 1.0000 - val_loss: 4.8040 - val_accuracy: 0.3211\n",
      "Epoch 83/100\n",
      "107/107 [==============================] - 0s 961us/step - loss: 4.3292e-04 - accuracy: 0.9997 - val_loss: 4.8522 - val_accuracy: 0.3237\n",
      "Epoch 84/100\n",
      "107/107 [==============================] - 0s 970us/step - loss: 3.3219e-04 - accuracy: 1.0000 - val_loss: 4.8952 - val_accuracy: 0.3289\n",
      "Epoch 85/100\n",
      "107/107 [==============================] - 0s 942us/step - loss: 2.4894e-04 - accuracy: 1.0000 - val_loss: 4.9514 - val_accuracy: 0.3211\n",
      "Epoch 86/100\n",
      "107/107 [==============================] - 0s 957us/step - loss: 2.9319e-04 - accuracy: 1.0000 - val_loss: 4.9779 - val_accuracy: 0.3263\n",
      "Epoch 87/100\n",
      "107/107 [==============================] - 0s 976us/step - loss: 2.3493e-04 - accuracy: 1.0000 - val_loss: 5.0255 - val_accuracy: 0.3263\n",
      "Epoch 88/100\n",
      "107/107 [==============================] - 0s 978us/step - loss: 2.3230e-04 - accuracy: 1.0000 - val_loss: 5.0790 - val_accuracy: 0.3211\n",
      "Epoch 89/100\n",
      "107/107 [==============================] - 0s 955us/step - loss: 2.4354e-04 - accuracy: 1.0000 - val_loss: 5.1195 - val_accuracy: 0.3211\n",
      "Epoch 90/100\n",
      "107/107 [==============================] - 0s 970us/step - loss: 2.7335e-04 - accuracy: 1.0000 - val_loss: 5.1701 - val_accuracy: 0.3237\n",
      "Epoch 91/100\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 2.6441e-04 - accuracy: 1.0000 - val_loss: 5.1984 - val_accuracy: 0.3263\n",
      "Epoch 92/100\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 2.3686e-04 - accuracy: 1.0000 - val_loss: 5.2353 - val_accuracy: 0.3237\n",
      "Epoch 93/100\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.7594e-04 - accuracy: 1.0000 - val_loss: 5.2788 - val_accuracy: 0.3263\n",
      "Epoch 94/100\n",
      "107/107 [==============================] - 0s 977us/step - loss: 1.8173e-04 - accuracy: 1.0000 - val_loss: 5.3069 - val_accuracy: 0.3263\n",
      "Epoch 95/100\n",
      "107/107 [==============================] - 0s 984us/step - loss: 1.6836e-04 - accuracy: 1.0000 - val_loss: 5.3547 - val_accuracy: 0.3316\n",
      "Epoch 96/100\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 2.0105e-04 - accuracy: 1.0000 - val_loss: 5.3908 - val_accuracy: 0.3316\n",
      "Epoch 97/100\n",
      "107/107 [==============================] - 0s 978us/step - loss: 1.2468e-04 - accuracy: 1.0000 - val_loss: 5.4331 - val_accuracy: 0.3289\n",
      "Epoch 98/100\n",
      "107/107 [==============================] - 0s 979us/step - loss: 1.7910e-04 - accuracy: 1.0000 - val_loss: 5.4518 - val_accuracy: 0.3316\n",
      "Epoch 99/100\n",
      "107/107 [==============================] - 0s 942us/step - loss: 1.3548e-04 - accuracy: 1.0000 - val_loss: 5.4793 - val_accuracy: 0.3316\n",
      "Epoch 100/100\n",
      "107/107 [==============================] - 0s 955us/step - loss: 1.2257e-04 - accuracy: 1.0000 - val_loss: 5.5208 - val_accuracy: 0.3342\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(maxWords, 8, input_length = maxLen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(5, activation = 'softmax'))\n",
    "model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "hist = model.fit(x,y,epochs = 100, validation_split = 0.1)\n",
    "hist = hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(len(hist['val_loss'])),hist['val_loss'])\n",
    "plt.figure()\n",
    "plt.plot(range(len(hist['val_accuracy'])),hist['val_accuracy'])\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel(embeddingN):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(maxWords, embeddingN, input_length = maxLen))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(5, activation = 'softmax'))\n",
    "    model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    hist = model.fit(x,y,epochs = 10, validation_split = 0.1)\n",
    "    hist = hist.history\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.5854 - accuracy: 0.2580 - val_loss: 1.5766 - val_accuracy: 0.2500\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 846us/step - loss: 1.5497 - accuracy: 0.2835 - val_loss: 1.5621 - val_accuracy: 0.2474\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 816us/step - loss: 1.5252 - accuracy: 0.2996 - val_loss: 1.5414 - val_accuracy: 0.2711\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 860us/step - loss: 1.5019 - accuracy: 0.3332 - val_loss: 1.5255 - val_accuracy: 0.2658\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 803us/step - loss: 1.4840 - accuracy: 0.3452 - val_loss: 1.5153 - val_accuracy: 0.2737\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 869us/step - loss: 1.4705 - accuracy: 0.3596 - val_loss: 1.5124 - val_accuracy: 0.2921\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 808us/step - loss: 1.4587 - accuracy: 0.3736 - val_loss: 1.5096 - val_accuracy: 0.2868\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 865us/step - loss: 1.4468 - accuracy: 0.3920 - val_loss: 1.5080 - val_accuracy: 0.3000\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 796us/step - loss: 1.4342 - accuracy: 0.4014 - val_loss: 1.5082 - val_accuracy: 0.2868\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 815us/step - loss: 1.4212 - accuracy: 0.4190 - val_loss: 1.5073 - val_accuracy: 0.2842\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.5790 - accuracy: 0.2598 - val_loss: 1.5714 - val_accuracy: 0.2605\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 869us/step - loss: 1.5339 - accuracy: 0.2958 - val_loss: 1.5471 - val_accuracy: 0.2789\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 883us/step - loss: 1.5011 - accuracy: 0.3370 - val_loss: 1.5285 - val_accuracy: 0.2842\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 883us/step - loss: 1.4778 - accuracy: 0.3540 - val_loss: 1.5235 - val_accuracy: 0.2763\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 853us/step - loss: 1.4600 - accuracy: 0.3736 - val_loss: 1.5191 - val_accuracy: 0.2711\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 896us/step - loss: 1.4414 - accuracy: 0.3958 - val_loss: 1.5158 - val_accuracy: 0.2921\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 865us/step - loss: 1.4216 - accuracy: 0.4260 - val_loss: 1.5183 - val_accuracy: 0.2974\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 845us/step - loss: 1.4004 - accuracy: 0.4441 - val_loss: 1.5139 - val_accuracy: 0.2947\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 855us/step - loss: 1.3777 - accuracy: 0.4675 - val_loss: 1.5127 - val_accuracy: 0.2947\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 847us/step - loss: 1.3530 - accuracy: 0.4874 - val_loss: 1.5124 - val_accuracy: 0.2921\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.5715 - accuracy: 0.2686 - val_loss: 1.5623 - val_accuracy: 0.2474\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 955us/step - loss: 1.5214 - accuracy: 0.3075 - val_loss: 1.5351 - val_accuracy: 0.2684\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 942us/step - loss: 1.4859 - accuracy: 0.3566 - val_loss: 1.5234 - val_accuracy: 0.2737\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 872us/step - loss: 1.4610 - accuracy: 0.3768 - val_loss: 1.5162 - val_accuracy: 0.3000\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 894us/step - loss: 1.4372 - accuracy: 0.4292 - val_loss: 1.5104 - val_accuracy: 0.3079\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 865us/step - loss: 1.4102 - accuracy: 0.4535 - val_loss: 1.5094 - val_accuracy: 0.3158\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 870us/step - loss: 1.3800 - accuracy: 0.4868 - val_loss: 1.5022 - val_accuracy: 0.2974\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 874us/step - loss: 1.3465 - accuracy: 0.5044 - val_loss: 1.4993 - val_accuracy: 0.3053\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 918us/step - loss: 1.3099 - accuracy: 0.5453 - val_loss: 1.4950 - val_accuracy: 0.3132\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.2721 - accuracy: 0.5644 - val_loss: 1.4902 - val_accuracy: 0.3105\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.5744 - accuracy: 0.2595 - val_loss: 1.5646 - val_accuracy: 0.2395\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 994us/step - loss: 1.5165 - accuracy: 0.3180 - val_loss: 1.5397 - val_accuracy: 0.2684\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 965us/step - loss: 1.4809 - accuracy: 0.3868 - val_loss: 1.5335 - val_accuracy: 0.2579\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.4538 - accuracy: 0.3994 - val_loss: 1.5278 - val_accuracy: 0.2737\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.4237 - accuracy: 0.4669 - val_loss: 1.5280 - val_accuracy: 0.2632\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 985us/step - loss: 1.3908 - accuracy: 0.4918 - val_loss: 1.5294 - val_accuracy: 0.2632\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 925us/step - loss: 1.3517 - accuracy: 0.5208 - val_loss: 1.5293 - val_accuracy: 0.2684\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 948us/step - loss: 1.3074 - accuracy: 0.5638 - val_loss: 1.5291 - val_accuracy: 0.2711\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 880us/step - loss: 1.2587 - accuracy: 0.5945 - val_loss: 1.5325 - val_accuracy: 0.2711\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 866us/step - loss: 1.2074 - accuracy: 0.6197 - val_loss: 1.5414 - val_accuracy: 0.2789\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.5624 - accuracy: 0.2700 - val_loss: 1.5557 - val_accuracy: 0.2684\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.5064 - accuracy: 0.3341 - val_loss: 1.5299 - val_accuracy: 0.2842\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 938us/step - loss: 1.4725 - accuracy: 0.3815 - val_loss: 1.5266 - val_accuracy: 0.2789\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 978us/step - loss: 1.4440 - accuracy: 0.4125 - val_loss: 1.5248 - val_accuracy: 0.3000\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 954us/step - loss: 1.4109 - accuracy: 0.4561 - val_loss: 1.5216 - val_accuracy: 0.2947\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 950us/step - loss: 1.3720 - accuracy: 0.5108 - val_loss: 1.5221 - val_accuracy: 0.3000\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.3259 - accuracy: 0.5410 - val_loss: 1.5241 - val_accuracy: 0.2789\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 926us/step - loss: 1.2751 - accuracy: 0.5916 - val_loss: 1.5211 - val_accuracy: 0.2737\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 894us/step - loss: 1.2200 - accuracy: 0.6238 - val_loss: 1.5291 - val_accuracy: 0.2816\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 909us/step - loss: 1.1627 - accuracy: 0.6556 - val_loss: 1.5317 - val_accuracy: 0.2789\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.5608 - accuracy: 0.2753 - val_loss: 1.5503 - val_accuracy: 0.2684\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 939us/step - loss: 1.5032 - accuracy: 0.3125 - val_loss: 1.5309 - val_accuracy: 0.2711\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 930us/step - loss: 1.4679 - accuracy: 0.3707 - val_loss: 1.5255 - val_accuracy: 0.2789\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 937us/step - loss: 1.4344 - accuracy: 0.4412 - val_loss: 1.5181 - val_accuracy: 0.2816\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 975us/step - loss: 1.3918 - accuracy: 0.4865 - val_loss: 1.5138 - val_accuracy: 0.2737\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 939us/step - loss: 1.3401 - accuracy: 0.5404 - val_loss: 1.5016 - val_accuracy: 0.3000\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 952us/step - loss: 1.2808 - accuracy: 0.5971 - val_loss: 1.4996 - val_accuracy: 0.2974\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 0s 958us/step - loss: 1.2127 - accuracy: 0.6434 - val_loss: 1.4947 - val_accuracy: 0.3158\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 888us/step - loss: 1.1416 - accuracy: 0.6755 - val_loss: 1.4867 - val_accuracy: 0.3000\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 884us/step - loss: 1.0666 - accuracy: 0.7106 - val_loss: 1.4950 - val_accuracy: 0.2895\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.5709 - accuracy: 0.2683 - val_loss: 1.5646 - val_accuracy: 0.2368\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 982us/step - loss: 1.5068 - accuracy: 0.3215 - val_loss: 1.5260 - val_accuracy: 0.2737\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 940us/step - loss: 1.4629 - accuracy: 0.3909 - val_loss: 1.5193 - val_accuracy: 0.2842\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 943us/step - loss: 1.4242 - accuracy: 0.4377 - val_loss: 1.5139 - val_accuracy: 0.2921\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 926us/step - loss: 1.3773 - accuracy: 0.5123 - val_loss: 1.5080 - val_accuracy: 0.3184\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 927us/step - loss: 1.3205 - accuracy: 0.5497 - val_loss: 1.4977 - val_accuracy: 0.3237\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 938us/step - loss: 1.2545 - accuracy: 0.6062 - val_loss: 1.4946 - val_accuracy: 0.3395\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 973us/step - loss: 1.1828 - accuracy: 0.6524 - val_loss: 1.4859 - val_accuracy: 0.3237\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 937us/step - loss: 1.1059 - accuracy: 0.6987 - val_loss: 1.4843 - val_accuracy: 0.3421\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 938us/step - loss: 1.0255 - accuracy: 0.7382 - val_loss: 1.4866 - val_accuracy: 0.3658\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.5612 - accuracy: 0.2741 - val_loss: 1.5462 - val_accuracy: 0.2816\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 966us/step - loss: 1.4949 - accuracy: 0.3370 - val_loss: 1.5241 - val_accuracy: 0.2632\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 965us/step - loss: 1.4590 - accuracy: 0.3929 - val_loss: 1.5209 - val_accuracy: 0.2553\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 931us/step - loss: 1.4199 - accuracy: 0.4590 - val_loss: 1.5196 - val_accuracy: 0.2500\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 961us/step - loss: 1.3702 - accuracy: 0.5132 - val_loss: 1.5084 - val_accuracy: 0.2974\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 941us/step - loss: 1.3100 - accuracy: 0.5822 - val_loss: 1.5101 - val_accuracy: 0.3026\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 950us/step - loss: 1.2404 - accuracy: 0.6276 - val_loss: 1.5101 - val_accuracy: 0.3026\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 922us/step - loss: 1.1633 - accuracy: 0.6720 - val_loss: 1.5026 - val_accuracy: 0.3000\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 943us/step - loss: 1.0810 - accuracy: 0.7127 - val_loss: 1.5013 - val_accuracy: 0.3079\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 927us/step - loss: 0.9963 - accuracy: 0.7496 - val_loss: 1.5017 - val_accuracy: 0.3158\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.5589 - accuracy: 0.2718 - val_loss: 1.5581 - val_accuracy: 0.2658\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 994us/step - loss: 1.4935 - accuracy: 0.3382 - val_loss: 1.5345 - val_accuracy: 0.2684\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 973us/step - loss: 1.4503 - accuracy: 0.3973 - val_loss: 1.5230 - val_accuracy: 0.3158\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 987us/step - loss: 1.4060 - accuracy: 0.4854 - val_loss: 1.5159 - val_accuracy: 0.3105\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 963us/step - loss: 1.3482 - accuracy: 0.5471 - val_loss: 1.5191 - val_accuracy: 0.3184\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 980us/step - loss: 1.2787 - accuracy: 0.6083 - val_loss: 1.5106 - val_accuracy: 0.3237\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 963us/step - loss: 1.2017 - accuracy: 0.6536 - val_loss: 1.5004 - val_accuracy: 0.3158\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 977us/step - loss: 1.1155 - accuracy: 0.6966 - val_loss: 1.4941 - val_accuracy: 0.3158\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 965us/step - loss: 1.0251 - accuracy: 0.7393 - val_loss: 1.4936 - val_accuracy: 0.3263\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 958us/step - loss: 0.9349 - accuracy: 0.7753 - val_loss: 1.4900 - val_accuracy: 0.3342\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.5605 - accuracy: 0.2747 - val_loss: 1.5466 - val_accuracy: 0.2711\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.4941 - accuracy: 0.3353 - val_loss: 1.5223 - val_accuracy: 0.2895\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 997us/step - loss: 1.4525 - accuracy: 0.4172 - val_loss: 1.5233 - val_accuracy: 0.2895\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.4037 - accuracy: 0.4763 - val_loss: 1.5133 - val_accuracy: 0.3053\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.3422 - accuracy: 0.5655 - val_loss: 1.5043 - val_accuracy: 0.3105\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.2664 - accuracy: 0.6375 - val_loss: 1.4985 - val_accuracy: 0.3079\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 995us/step - loss: 1.1769 - accuracy: 0.6829 - val_loss: 1.4926 - val_accuracy: 0.3026\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.0826 - accuracy: 0.7279 - val_loss: 1.4919 - val_accuracy: 0.3184\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.9828 - accuracy: 0.7721 - val_loss: 1.4908 - val_accuracy: 0.3316\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.8823 - accuracy: 0.8113 - val_loss: 1.4913 - val_accuracy: 0.3237\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.5532 - accuracy: 0.2695 - val_loss: 1.5439 - val_accuracy: 0.2553\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.4874 - accuracy: 0.3563 - val_loss: 1.5262 - val_accuracy: 0.2895\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.4441 - accuracy: 0.4213 - val_loss: 1.5224 - val_accuracy: 0.2684\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.3887 - accuracy: 0.4944 - val_loss: 1.5185 - val_accuracy: 0.3026\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.3193 - accuracy: 0.5948 - val_loss: 1.5162 - val_accuracy: 0.2868\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.2333 - accuracy: 0.6600 - val_loss: 1.5155 - val_accuracy: 0.3000\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.1355 - accuracy: 0.7104 - val_loss: 1.5056 - val_accuracy: 0.3211\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.0330 - accuracy: 0.7563 - val_loss: 1.5082 - val_accuracy: 0.3158\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.9265 - accuracy: 0.7929 - val_loss: 1.5175 - val_accuracy: 0.3211\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.8228 - accuracy: 0.8256 - val_loss: 1.5176 - val_accuracy: 0.3237\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.5486 - accuracy: 0.2847 - val_loss: 1.5418 - val_accuracy: 0.2763\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.4810 - accuracy: 0.3467 - val_loss: 1.5216 - val_accuracy: 0.2842\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.4360 - accuracy: 0.4406 - val_loss: 1.5157 - val_accuracy: 0.2921\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.3757 - accuracy: 0.5143 - val_loss: 1.5032 - val_accuracy: 0.3158\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.2981 - accuracy: 0.5910 - val_loss: 1.4886 - val_accuracy: 0.3474\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.2067 - accuracy: 0.6507 - val_loss: 1.4821 - val_accuracy: 0.3368\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.1036 - accuracy: 0.7033 - val_loss: 1.4689 - val_accuracy: 0.3526\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.9950 - accuracy: 0.7583 - val_loss: 1.4629 - val_accuracy: 0.3553\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.8882 - accuracy: 0.7990 - val_loss: 1.4589 - val_accuracy: 0.3447\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.7825 - accuracy: 0.8388 - val_loss: 1.4658 - val_accuracy: 0.3553\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.5544 - accuracy: 0.2776 - val_loss: 1.5416 - val_accuracy: 0.2658\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.4838 - accuracy: 0.3426 - val_loss: 1.5281 - val_accuracy: 0.2895\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.4374 - accuracy: 0.4356 - val_loss: 1.5290 - val_accuracy: 0.2974\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.3753 - accuracy: 0.5208 - val_loss: 1.5135 - val_accuracy: 0.2816\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.2973 - accuracy: 0.6138 - val_loss: 1.5151 - val_accuracy: 0.3000\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.2031 - accuracy: 0.6732 - val_loss: 1.5015 - val_accuracy: 0.3053\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.0944 - accuracy: 0.7270 - val_loss: 1.4893 - val_accuracy: 0.3079\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.9787 - accuracy: 0.7812 - val_loss: 1.4833 - val_accuracy: 0.3342\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.8626 - accuracy: 0.8113 - val_loss: 1.4791 - val_accuracy: 0.3132\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.7506 - accuracy: 0.8479 - val_loss: 1.4874 - val_accuracy: 0.3158\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.5461 - accuracy: 0.2753 - val_loss: 1.5398 - val_accuracy: 0.2737\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.4822 - accuracy: 0.3549 - val_loss: 1.5220 - val_accuracy: 0.2816\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.4364 - accuracy: 0.4470 - val_loss: 1.5266 - val_accuracy: 0.2947\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.3732 - accuracy: 0.5173 - val_loss: 1.5128 - val_accuracy: 0.3184\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.2914 - accuracy: 0.6264 - val_loss: 1.5007 - val_accuracy: 0.3184\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.1916 - accuracy: 0.6738 - val_loss: 1.4873 - val_accuracy: 0.3184\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.0792 - accuracy: 0.7349 - val_loss: 1.4808 - val_accuracy: 0.3368\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.9600 - accuracy: 0.7885 - val_loss: 1.4726 - val_accuracy: 0.3342\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.8406 - accuracy: 0.8300 - val_loss: 1.4687 - val_accuracy: 0.3421\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.7267 - accuracy: 0.8666 - val_loss: 1.4695 - val_accuracy: 0.3447\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.5472 - accuracy: 0.2727 - val_loss: 1.5441 - val_accuracy: 0.2789\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.4782 - accuracy: 0.3742 - val_loss: 1.5173 - val_accuracy: 0.2842\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.4243 - accuracy: 0.4465 - val_loss: 1.5070 - val_accuracy: 0.3000\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.3512 - accuracy: 0.5477 - val_loss: 1.4992 - val_accuracy: 0.3079\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.2570 - accuracy: 0.6314 - val_loss: 1.4794 - val_accuracy: 0.3184\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.1470 - accuracy: 0.6875 - val_loss: 1.4581 - val_accuracy: 0.3342\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.0253 - accuracy: 0.7434 - val_loss: 1.4571 - val_accuracy: 0.3368\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.9020 - accuracy: 0.7949 - val_loss: 1.4573 - val_accuracy: 0.3368\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.7827 - accuracy: 0.8388 - val_loss: 1.4638 - val_accuracy: 0.3421\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6700 - accuracy: 0.8736 - val_loss: 1.4694 - val_accuracy: 0.3553\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.5498 - accuracy: 0.2744 - val_loss: 1.5357 - val_accuracy: 0.2763\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.4779 - accuracy: 0.3669 - val_loss: 1.5315 - val_accuracy: 0.2816\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.4264 - accuracy: 0.4576 - val_loss: 1.5271 - val_accuracy: 0.2711\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.3551 - accuracy: 0.5550 - val_loss: 1.5196 - val_accuracy: 0.2974\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.2612 - accuracy: 0.6378 - val_loss: 1.5055 - val_accuracy: 0.3026\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.1477 - accuracy: 0.7060 - val_loss: 1.4889 - val_accuracy: 0.3105\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.0237 - accuracy: 0.7575 - val_loss: 1.4829 - val_accuracy: 0.3368\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.8969 - accuracy: 0.8028 - val_loss: 1.4908 - val_accuracy: 0.3237\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.7741 - accuracy: 0.8438 - val_loss: 1.4842 - val_accuracy: 0.3500\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6588 - accuracy: 0.8789 - val_loss: 1.4969 - val_accuracy: 0.3605\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.5449 - accuracy: 0.2949 - val_loss: 1.5301 - val_accuracy: 0.2605\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.4744 - accuracy: 0.3651 - val_loss: 1.5294 - val_accuracy: 0.2605\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.4196 - accuracy: 0.4526 - val_loss: 1.5128 - val_accuracy: 0.2895\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.3434 - accuracy: 0.5571 - val_loss: 1.4994 - val_accuracy: 0.3079\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.2438 - accuracy: 0.6533 - val_loss: 1.4922 - val_accuracy: 0.3263\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.1245 - accuracy: 0.7212 - val_loss: 1.4900 - val_accuracy: 0.3158\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.9929 - accuracy: 0.7797 - val_loss: 1.4696 - val_accuracy: 0.3211\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.8580 - accuracy: 0.8291 - val_loss: 1.4654 - val_accuracy: 0.3368\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.7291 - accuracy: 0.8625 - val_loss: 1.4681 - val_accuracy: 0.3316\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6109 - accuracy: 0.8947 - val_loss: 1.4746 - val_accuracy: 0.3289\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.5467 - accuracy: 0.2785 - val_loss: 1.5311 - val_accuracy: 0.2658\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.4765 - accuracy: 0.3549 - val_loss: 1.5238 - val_accuracy: 0.2711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.4213 - accuracy: 0.4734 - val_loss: 1.5178 - val_accuracy: 0.2789\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.3440 - accuracy: 0.5606 - val_loss: 1.5037 - val_accuracy: 0.3026\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.2408 - accuracy: 0.6635 - val_loss: 1.4912 - val_accuracy: 0.3237\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.1166 - accuracy: 0.7358 - val_loss: 1.4785 - val_accuracy: 0.3395\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.9796 - accuracy: 0.7820 - val_loss: 1.4638 - val_accuracy: 0.3474\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.8401 - accuracy: 0.8370 - val_loss: 1.4630 - val_accuracy: 0.3553\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.7077 - accuracy: 0.8736 - val_loss: 1.4647 - val_accuracy: 0.3500\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.5873 - accuracy: 0.9064 - val_loss: 1.4725 - val_accuracy: 0.3579\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.5400 - accuracy: 0.2861 - val_loss: 1.5348 - val_accuracy: 0.2605\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.4701 - accuracy: 0.3678 - val_loss: 1.5344 - val_accuracy: 0.2737\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.4109 - accuracy: 0.4845 - val_loss: 1.5198 - val_accuracy: 0.2684\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.3264 - accuracy: 0.5708 - val_loss: 1.5121 - val_accuracy: 0.2895\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.2157 - accuracy: 0.6793 - val_loss: 1.5069 - val_accuracy: 0.2947\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.0857 - accuracy: 0.7320 - val_loss: 1.4962 - val_accuracy: 0.3316\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.9454 - accuracy: 0.8005 - val_loss: 1.4910 - val_accuracy: 0.3263\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.8043 - accuracy: 0.8435 - val_loss: 1.4958 - val_accuracy: 0.3184\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6724 - accuracy: 0.8894 - val_loss: 1.5064 - val_accuracy: 0.3316\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.5529 - accuracy: 0.9184 - val_loss: 1.5176 - val_accuracy: 0.3184\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.5442 - accuracy: 0.2809 - val_loss: 1.5414 - val_accuracy: 0.2632\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.4714 - accuracy: 0.3692 - val_loss: 1.5375 - val_accuracy: 0.2711\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.4102 - accuracy: 0.4699 - val_loss: 1.5067 - val_accuracy: 0.2921\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.3238 - accuracy: 0.5787 - val_loss: 1.4959 - val_accuracy: 0.3211\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.2072 - accuracy: 0.6750 - val_loss: 1.4806 - val_accuracy: 0.3237\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.0718 - accuracy: 0.7387 - val_loss: 1.4709 - val_accuracy: 0.3395\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.9264 - accuracy: 0.8034 - val_loss: 1.4641 - val_accuracy: 0.3526\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.7833 - accuracy: 0.8549 - val_loss: 1.4590 - val_accuracy: 0.3421\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6489 - accuracy: 0.8929 - val_loss: 1.4724 - val_accuracy: 0.3421\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.5287 - accuracy: 0.9257 - val_loss: 1.4871 - val_accuracy: 0.3500\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.5413 - accuracy: 0.2835 - val_loss: 1.5273 - val_accuracy: 0.2737\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.4688 - accuracy: 0.3645 - val_loss: 1.5146 - val_accuracy: 0.2763\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.4033 - accuracy: 0.4857 - val_loss: 1.5111 - val_accuracy: 0.2921\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.3095 - accuracy: 0.5872 - val_loss: 1.4853 - val_accuracy: 0.3158\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.1878 - accuracy: 0.6875 - val_loss: 1.4733 - val_accuracy: 0.3342\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.0464 - accuracy: 0.7539 - val_loss: 1.4475 - val_accuracy: 0.3447\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.8995 - accuracy: 0.8092 - val_loss: 1.4333 - val_accuracy: 0.3763\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.7553 - accuracy: 0.8616 - val_loss: 1.4369 - val_accuracy: 0.3684\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6237 - accuracy: 0.8903 - val_loss: 1.4415 - val_accuracy: 0.3789\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.5069 - accuracy: 0.9219 - val_loss: 1.4538 - val_accuracy: 0.3842\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.5450 - accuracy: 0.2776 - val_loss: 1.5273 - val_accuracy: 0.2842\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.4680 - accuracy: 0.3871 - val_loss: 1.5136 - val_accuracy: 0.2947\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.4017 - accuracy: 0.4953 - val_loss: 1.5123 - val_accuracy: 0.3026\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.3041 - accuracy: 0.5942 - val_loss: 1.4916 - val_accuracy: 0.2921\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.1794 - accuracy: 0.7016 - val_loss: 1.4811 - val_accuracy: 0.3105\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.0341 - accuracy: 0.7583 - val_loss: 1.4665 - val_accuracy: 0.3132\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.8819 - accuracy: 0.8204 - val_loss: 1.4694 - val_accuracy: 0.3132\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.7352 - accuracy: 0.8675 - val_loss: 1.4677 - val_accuracy: 0.3263\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6001 - accuracy: 0.9029 - val_loss: 1.4814 - val_accuracy: 0.3289\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.4826 - accuracy: 0.9353 - val_loss: 1.4949 - val_accuracy: 0.3211\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.5419 - accuracy: 0.2905 - val_loss: 1.5292 - val_accuracy: 0.2763\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.4665 - accuracy: 0.3771 - val_loss: 1.5214 - val_accuracy: 0.2895\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.3954 - accuracy: 0.4836 - val_loss: 1.5066 - val_accuracy: 0.3000\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.2940 - accuracy: 0.6106 - val_loss: 1.4898 - val_accuracy: 0.3132\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.1602 - accuracy: 0.7019 - val_loss: 1.4754 - val_accuracy: 0.3263\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.0094 - accuracy: 0.7706 - val_loss: 1.4560 - val_accuracy: 0.3447\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.8534 - accuracy: 0.8291 - val_loss: 1.4492 - val_accuracy: 0.3553\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.7060 - accuracy: 0.8698 - val_loss: 1.4530 - val_accuracy: 0.3684\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.5709 - accuracy: 0.9078 - val_loss: 1.4691 - val_accuracy: 0.3684\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.4541 - accuracy: 0.9374 - val_loss: 1.4772 - val_accuracy: 0.3711\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.5375 - accuracy: 0.2987 - val_loss: 1.5379 - val_accuracy: 0.2868\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.4657 - accuracy: 0.4017 - val_loss: 1.5254 - val_accuracy: 0.2737\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.3948 - accuracy: 0.5041 - val_loss: 1.5134 - val_accuracy: 0.2947\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.2896 - accuracy: 0.6243 - val_loss: 1.4969 - val_accuracy: 0.3421\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.1519 - accuracy: 0.7080 - val_loss: 1.4758 - val_accuracy: 0.3263\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.9964 - accuracy: 0.7741 - val_loss: 1.4582 - val_accuracy: 0.3553\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.8375 - accuracy: 0.8341 - val_loss: 1.4492 - val_accuracy: 0.3474\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6857 - accuracy: 0.8844 - val_loss: 1.4538 - val_accuracy: 0.3526\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.5495 - accuracy: 0.9172 - val_loss: 1.4642 - val_accuracy: 0.3553\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.4316 - accuracy: 0.9432 - val_loss: 1.4807 - val_accuracy: 0.3605\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.5385 - accuracy: 0.2873 - val_loss: 1.5319 - val_accuracy: 0.2842\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.4636 - accuracy: 0.4005 - val_loss: 1.5208 - val_accuracy: 0.3000\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.3883 - accuracy: 0.4997 - val_loss: 1.5134 - val_accuracy: 0.2895\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.2827 - accuracy: 0.6381 - val_loss: 1.5012 - val_accuracy: 0.3184\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.1434 - accuracy: 0.7147 - val_loss: 1.4895 - val_accuracy: 0.3368\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.9854 - accuracy: 0.7803 - val_loss: 1.4785 - val_accuracy: 0.3368\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.8237 - accuracy: 0.8441 - val_loss: 1.4725 - val_accuracy: 0.3526\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6696 - accuracy: 0.8865 - val_loss: 1.4772 - val_accuracy: 0.3474\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5319 - accuracy: 0.9228 - val_loss: 1.4900 - val_accuracy: 0.3368\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.4155 - accuracy: 0.9485 - val_loss: 1.5132 - val_accuracy: 0.3368\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.5352 - accuracy: 0.2882 - val_loss: 1.5417 - val_accuracy: 0.2658\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.4624 - accuracy: 0.3929 - val_loss: 1.5255 - val_accuracy: 0.2816\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.3845 - accuracy: 0.4980 - val_loss: 1.5077 - val_accuracy: 0.2895\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 1.2688 - accuracy: 0.6343 - val_loss: 1.4771 - val_accuracy: 0.3237\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.1213 - accuracy: 0.7288 - val_loss: 1.4581 - val_accuracy: 0.3368\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.9581 - accuracy: 0.7932 - val_loss: 1.4389 - val_accuracy: 0.3605\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.7908 - accuracy: 0.8552 - val_loss: 1.4371 - val_accuracy: 0.3553\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6362 - accuracy: 0.8988 - val_loss: 1.4351 - val_accuracy: 0.3789\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.9283 - val_loss: 1.4493 - val_accuracy: 0.3553\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.3855 - accuracy: 0.9503 - val_loss: 1.4758 - val_accuracy: 0.3605\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.5422 - accuracy: 0.2774 - val_loss: 1.5390 - val_accuracy: 0.2789\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.4609 - accuracy: 0.3917 - val_loss: 1.5176 - val_accuracy: 0.2868\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.3814 - accuracy: 0.5076 - val_loss: 1.4977 - val_accuracy: 0.3342\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.2633 - accuracy: 0.6442 - val_loss: 1.4706 - val_accuracy: 0.3421\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.1126 - accuracy: 0.7212 - val_loss: 1.4437 - val_accuracy: 0.3500\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.9449 - accuracy: 0.7858 - val_loss: 1.4180 - val_accuracy: 0.3711\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.7773 - accuracy: 0.8566 - val_loss: 1.4138 - val_accuracy: 0.3553\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6221 - accuracy: 0.9014 - val_loss: 1.4043 - val_accuracy: 0.3895\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.9336 - val_loss: 1.4141 - val_accuracy: 0.3763\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3743 - accuracy: 0.9573 - val_loss: 1.4330 - val_accuracy: 0.3579\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.5311 - accuracy: 0.2937 - val_loss: 1.5363 - val_accuracy: 0.2658\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.4583 - accuracy: 0.3932 - val_loss: 1.5220 - val_accuracy: 0.2895\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.3767 - accuracy: 0.5105 - val_loss: 1.5066 - val_accuracy: 0.3105\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.2568 - accuracy: 0.6486 - val_loss: 1.4856 - val_accuracy: 0.3263\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.1021 - accuracy: 0.7472 - val_loss: 1.4682 - val_accuracy: 0.3316\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.9286 - accuracy: 0.8081 - val_loss: 1.4465 - val_accuracy: 0.3447\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.7575 - accuracy: 0.8637 - val_loss: 1.4426 - val_accuracy: 0.3447\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5994 - accuracy: 0.9096 - val_loss: 1.4527 - val_accuracy: 0.3421\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.9386 - val_loss: 1.4674 - val_accuracy: 0.3421\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3516 - accuracy: 0.9628 - val_loss: 1.4897 - val_accuracy: 0.3526\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.5389 - accuracy: 0.2832 - val_loss: 1.5247 - val_accuracy: 0.2816\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.4583 - accuracy: 0.4037 - val_loss: 1.5182 - val_accuracy: 0.2895\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.3752 - accuracy: 0.5339 - val_loss: 1.5088 - val_accuracy: 0.3053\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.2538 - accuracy: 0.6580 - val_loss: 1.4951 - val_accuracy: 0.3447\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.0965 - accuracy: 0.7349 - val_loss: 1.4784 - val_accuracy: 0.3237\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.9212 - accuracy: 0.8110 - val_loss: 1.4638 - val_accuracy: 0.3368\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.7487 - accuracy: 0.8672 - val_loss: 1.4696 - val_accuracy: 0.3395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5907 - accuracy: 0.9114 - val_loss: 1.4781 - val_accuracy: 0.3474\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.9377 - val_loss: 1.4961 - val_accuracy: 0.3474\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.9643 - val_loss: 1.5257 - val_accuracy: 0.3474\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.5387 - accuracy: 0.2899 - val_loss: 1.5229 - val_accuracy: 0.2711\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.4565 - accuracy: 0.3929 - val_loss: 1.5257 - val_accuracy: 0.2895\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.3737 - accuracy: 0.5334 - val_loss: 1.5095 - val_accuracy: 0.3263\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.2466 - accuracy: 0.6530 - val_loss: 1.4836 - val_accuracy: 0.3395\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.0851 - accuracy: 0.7422 - val_loss: 1.4580 - val_accuracy: 0.3658\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.9047 - accuracy: 0.8256 - val_loss: 1.4511 - val_accuracy: 0.3632\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.7266 - accuracy: 0.8809 - val_loss: 1.4453 - val_accuracy: 0.3658\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5660 - accuracy: 0.9157 - val_loss: 1.4522 - val_accuracy: 0.3737\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.9459 - val_loss: 1.4609 - val_accuracy: 0.3711\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3210 - accuracy: 0.9681 - val_loss: 1.4918 - val_accuracy: 0.3789\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.5359 - accuracy: 0.2838 - val_loss: 1.5269 - val_accuracy: 0.2737\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.4550 - accuracy: 0.3976 - val_loss: 1.5194 - val_accuracy: 0.2921\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.3689 - accuracy: 0.5527 - val_loss: 1.5155 - val_accuracy: 0.3132\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.2374 - accuracy: 0.6633 - val_loss: 1.5093 - val_accuracy: 0.3289\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.0733 - accuracy: 0.7411 - val_loss: 1.4911 - val_accuracy: 0.3211\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.8921 - accuracy: 0.8274 - val_loss: 1.4821 - val_accuracy: 0.3289\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.7144 - accuracy: 0.8809 - val_loss: 1.4855 - val_accuracy: 0.3368\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.9210 - val_loss: 1.5011 - val_accuracy: 0.3368\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.9468 - val_loss: 1.5315 - val_accuracy: 0.3553\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.9664 - val_loss: 1.5677 - val_accuracy: 0.3553\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.5322 - accuracy: 0.2873 - val_loss: 1.5235 - val_accuracy: 0.2684\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.4523 - accuracy: 0.3973 - val_loss: 1.5149 - val_accuracy: 0.2684\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.3605 - accuracy: 0.5190 - val_loss: 1.5041 - val_accuracy: 0.3184\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.2264 - accuracy: 0.6688 - val_loss: 1.4828 - val_accuracy: 0.3237\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.0570 - accuracy: 0.7604 - val_loss: 1.4704 - val_accuracy: 0.3289\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.8728 - accuracy: 0.8280 - val_loss: 1.4535 - val_accuracy: 0.3395\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6963 - accuracy: 0.8827 - val_loss: 1.4593 - val_accuracy: 0.3553\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.9201 - val_loss: 1.4666 - val_accuracy: 0.3605\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4030 - accuracy: 0.9508 - val_loss: 1.4899 - val_accuracy: 0.3526\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.2955 - accuracy: 0.9684 - val_loss: 1.5220 - val_accuracy: 0.3526\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.5349 - accuracy: 0.2888 - val_loss: 1.5384 - val_accuracy: 0.2789\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.4526 - accuracy: 0.3988 - val_loss: 1.5270 - val_accuracy: 0.2868\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.3592 - accuracy: 0.5331 - val_loss: 1.5126 - val_accuracy: 0.2974\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.2214 - accuracy: 0.6829 - val_loss: 1.4838 - val_accuracy: 0.3368\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.0488 - accuracy: 0.7727 - val_loss: 1.4661 - val_accuracy: 0.3263\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.8599 - accuracy: 0.8370 - val_loss: 1.4623 - val_accuracy: 0.3079\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6784 - accuracy: 0.8909 - val_loss: 1.4602 - val_accuracy: 0.3553\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.9298 - val_loss: 1.4716 - val_accuracy: 0.3474\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3864 - accuracy: 0.9576 - val_loss: 1.4881 - val_accuracy: 0.3447\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.2814 - accuracy: 0.9734 - val_loss: 1.5143 - val_accuracy: 0.3500\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.5316 - accuracy: 0.2858 - val_loss: 1.5374 - val_accuracy: 0.2658\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.4507 - accuracy: 0.4119 - val_loss: 1.5218 - val_accuracy: 0.2579\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.3568 - accuracy: 0.5565 - val_loss: 1.5066 - val_accuracy: 0.2816\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.2142 - accuracy: 0.6688 - val_loss: 1.4723 - val_accuracy: 0.3158\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.0372 - accuracy: 0.7680 - val_loss: 1.4570 - val_accuracy: 0.3316\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.8454 - accuracy: 0.8441 - val_loss: 1.4415 - val_accuracy: 0.3526\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6626 - accuracy: 0.8958 - val_loss: 1.4478 - val_accuracy: 0.3579\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.9315 - val_loss: 1.4504 - val_accuracy: 0.3763\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3717 - accuracy: 0.9596 - val_loss: 1.4743 - val_accuracy: 0.3684\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.2682 - accuracy: 0.9754 - val_loss: 1.5001 - val_accuracy: 0.3789\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.5403 - accuracy: 0.2794 - val_loss: 1.5233 - val_accuracy: 0.2868\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.4505 - accuracy: 0.4108 - val_loss: 1.5140 - val_accuracy: 0.2974\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.3553 - accuracy: 0.5644 - val_loss: 1.4899 - val_accuracy: 0.3211\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.2100 - accuracy: 0.6849 - val_loss: 1.4749 - val_accuracy: 0.3395\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.0296 - accuracy: 0.7744 - val_loss: 1.4496 - val_accuracy: 0.3553\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.8372 - accuracy: 0.8470 - val_loss: 1.4455 - val_accuracy: 0.3474\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6549 - accuracy: 0.8953 - val_loss: 1.4448 - val_accuracy: 0.3605\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4962 - accuracy: 0.9277 - val_loss: 1.4592 - val_accuracy: 0.3579\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.9599 - val_loss: 1.4861 - val_accuracy: 0.3579\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.2650 - accuracy: 0.9743 - val_loss: 1.5169 - val_accuracy: 0.3500\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.5398 - accuracy: 0.2800 - val_loss: 1.5297 - val_accuracy: 0.2921\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.4504 - accuracy: 0.3985 - val_loss: 1.5168 - val_accuracy: 0.3105\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.3513 - accuracy: 0.5565 - val_loss: 1.4983 - val_accuracy: 0.3105\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.2039 - accuracy: 0.6922 - val_loss: 1.4813 - val_accuracy: 0.3237\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.0197 - accuracy: 0.7706 - val_loss: 1.4620 - val_accuracy: 0.3342\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.8236 - accuracy: 0.8482 - val_loss: 1.4564 - val_accuracy: 0.3684\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6384 - accuracy: 0.9055 - val_loss: 1.4689 - val_accuracy: 0.3474\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.9377 - val_loss: 1.4797 - val_accuracy: 0.3553\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3495 - accuracy: 0.9605 - val_loss: 1.5095 - val_accuracy: 0.3553\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.2491 - accuracy: 0.9783 - val_loss: 1.5403 - val_accuracy: 0.3421\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.5350 - accuracy: 0.2850 - val_loss: 1.5383 - val_accuracy: 0.2684\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.4472 - accuracy: 0.3982 - val_loss: 1.5241 - val_accuracy: 0.2974\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.3411 - accuracy: 0.5617 - val_loss: 1.4978 - val_accuracy: 0.3316\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.1862 - accuracy: 0.6908 - val_loss: 1.4613 - val_accuracy: 0.3553\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.9946 - accuracy: 0.7774 - val_loss: 1.4447 - val_accuracy: 0.3579\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.7999 - accuracy: 0.8584 - val_loss: 1.4384 - val_accuracy: 0.3763\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6162 - accuracy: 0.9011 - val_loss: 1.4419 - val_accuracy: 0.3711\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.9415 - val_loss: 1.4678 - val_accuracy: 0.3579\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.9617 - val_loss: 1.4898 - val_accuracy: 0.3553\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.2354 - accuracy: 0.9775 - val_loss: 1.5214 - val_accuracy: 0.3526\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.5327 - accuracy: 0.2917 - val_loss: 1.5333 - val_accuracy: 0.2684\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.4433 - accuracy: 0.4090 - val_loss: 1.5173 - val_accuracy: 0.3026\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.3342 - accuracy: 0.5705 - val_loss: 1.4901 - val_accuracy: 0.3263\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.1749 - accuracy: 0.7071 - val_loss: 1.4664 - val_accuracy: 0.3395\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.9803 - accuracy: 0.7858 - val_loss: 1.4349 - val_accuracy: 0.3658\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.7790 - accuracy: 0.8645 - val_loss: 1.4358 - val_accuracy: 0.3763\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5930 - accuracy: 0.9163 - val_loss: 1.4417 - val_accuracy: 0.3658\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.9476 - val_loss: 1.4626 - val_accuracy: 0.3684\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.9707 - val_loss: 1.4904 - val_accuracy: 0.3447\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.2195 - accuracy: 0.9824 - val_loss: 1.5238 - val_accuracy: 0.3500\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.5293 - accuracy: 0.2850 - val_loss: 1.5247 - val_accuracy: 0.2763\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.4479 - accuracy: 0.4172 - val_loss: 1.5210 - val_accuracy: 0.2842\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.3437 - accuracy: 0.5752 - val_loss: 1.5141 - val_accuracy: 0.3000\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.1888 - accuracy: 0.6908 - val_loss: 1.4868 - val_accuracy: 0.3211\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.9966 - accuracy: 0.7879 - val_loss: 1.4750 - val_accuracy: 0.3316\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.7931 - accuracy: 0.8578 - val_loss: 1.4666 - val_accuracy: 0.3263\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6048 - accuracy: 0.9154 - val_loss: 1.4785 - val_accuracy: 0.3500\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.9447 - val_loss: 1.5078 - val_accuracy: 0.3316\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3186 - accuracy: 0.9666 - val_loss: 1.5252 - val_accuracy: 0.3184\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.2223 - accuracy: 0.9813 - val_loss: 1.5729 - val_accuracy: 0.3316\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.5329 - accuracy: 0.2817 - val_loss: 1.5354 - val_accuracy: 0.2737\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.4441 - accuracy: 0.4201 - val_loss: 1.5137 - val_accuracy: 0.2895\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.3356 - accuracy: 0.5512 - val_loss: 1.5017 - val_accuracy: 0.3211\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.1772 - accuracy: 0.6984 - val_loss: 1.4796 - val_accuracy: 0.3237\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.9813 - accuracy: 0.7946 - val_loss: 1.4647 - val_accuracy: 0.3237\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.7767 - accuracy: 0.8648 - val_loss: 1.4563 - val_accuracy: 0.3368\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5901 - accuracy: 0.9111 - val_loss: 1.4669 - val_accuracy: 0.3263\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.9459 - val_loss: 1.4914 - val_accuracy: 0.3526\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.9681 - val_loss: 1.5333 - val_accuracy: 0.3263\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.2149 - accuracy: 0.9807 - val_loss: 1.5744 - val_accuracy: 0.3342\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.5338 - accuracy: 0.2826 - val_loss: 1.5392 - val_accuracy: 0.2789\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.4444 - accuracy: 0.4087 - val_loss: 1.5133 - val_accuracy: 0.3079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.3334 - accuracy: 0.5840 - val_loss: 1.5004 - val_accuracy: 0.3184\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.1683 - accuracy: 0.7168 - val_loss: 1.4906 - val_accuracy: 0.3579\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.9673 - accuracy: 0.7937 - val_loss: 1.4743 - val_accuracy: 0.3368\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.7577 - accuracy: 0.8724 - val_loss: 1.4730 - val_accuracy: 0.3474\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5656 - accuracy: 0.9225 - val_loss: 1.4903 - val_accuracy: 0.3500\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.9585 - val_loss: 1.5195 - val_accuracy: 0.3447\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.2855 - accuracy: 0.9710 - val_loss: 1.5430 - val_accuracy: 0.3579\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1950 - accuracy: 0.9842 - val_loss: 1.5924 - val_accuracy: 0.3395\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.5356 - accuracy: 0.2803 - val_loss: 1.5327 - val_accuracy: 0.2684\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.4433 - accuracy: 0.4178 - val_loss: 1.5193 - val_accuracy: 0.2816\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.3323 - accuracy: 0.5872 - val_loss: 1.5097 - val_accuracy: 0.3026\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.1655 - accuracy: 0.7194 - val_loss: 1.4894 - val_accuracy: 0.3105\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.9601 - accuracy: 0.8002 - val_loss: 1.4775 - val_accuracy: 0.3237\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.7499 - accuracy: 0.8760 - val_loss: 1.4793 - val_accuracy: 0.3447\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.9269 - val_loss: 1.4936 - val_accuracy: 0.3421\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4011 - accuracy: 0.9541 - val_loss: 1.5142 - val_accuracy: 0.3658\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.2798 - accuracy: 0.9745 - val_loss: 1.5560 - val_accuracy: 0.3658\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1906 - accuracy: 0.9842 - val_loss: 1.6101 - val_accuracy: 0.3500\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.5322 - accuracy: 0.2896 - val_loss: 1.5308 - val_accuracy: 0.2737\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.4427 - accuracy: 0.4254 - val_loss: 1.5149 - val_accuracy: 0.3105\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.3306 - accuracy: 0.5728 - val_loss: 1.5087 - val_accuracy: 0.2895\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.1640 - accuracy: 0.7185 - val_loss: 1.4859 - val_accuracy: 0.3211\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.9569 - accuracy: 0.8066 - val_loss: 1.4806 - val_accuracy: 0.3105\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.7443 - accuracy: 0.8780 - val_loss: 1.4786 - val_accuracy: 0.3263\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.9318 - val_loss: 1.4858 - val_accuracy: 0.3474\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.9585 - val_loss: 1.5129 - val_accuracy: 0.3395\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.2746 - accuracy: 0.9737 - val_loss: 1.5390 - val_accuracy: 0.3500\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1877 - accuracy: 0.9822 - val_loss: 1.5875 - val_accuracy: 0.3421\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.5310 - accuracy: 0.2929 - val_loss: 1.5213 - val_accuracy: 0.2658\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.4383 - accuracy: 0.4245 - val_loss: 1.5010 - val_accuracy: 0.2868\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.3191 - accuracy: 0.5907 - val_loss: 1.4949 - val_accuracy: 0.2789\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.1430 - accuracy: 0.7235 - val_loss: 1.4572 - val_accuracy: 0.3368\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.9313 - accuracy: 0.8209 - val_loss: 1.4444 - val_accuracy: 0.3763\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.7169 - accuracy: 0.8812 - val_loss: 1.4384 - val_accuracy: 0.3684\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.9310 - val_loss: 1.4469 - val_accuracy: 0.3632\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.9602 - val_loss: 1.4686 - val_accuracy: 0.3632\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.2555 - accuracy: 0.9754 - val_loss: 1.5052 - val_accuracy: 0.3500\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1717 - accuracy: 0.9860 - val_loss: 1.5404 - val_accuracy: 0.3500\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.5285 - accuracy: 0.2885 - val_loss: 1.5410 - val_accuracy: 0.2684\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.4371 - accuracy: 0.4318 - val_loss: 1.5111 - val_accuracy: 0.2816\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.3155 - accuracy: 0.6042 - val_loss: 1.5189 - val_accuracy: 0.3211\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.1406 - accuracy: 0.7206 - val_loss: 1.4697 - val_accuracy: 0.3395\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.9274 - accuracy: 0.8204 - val_loss: 1.4498 - val_accuracy: 0.3395\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.7121 - accuracy: 0.8850 - val_loss: 1.4416 - val_accuracy: 0.3526\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.9362 - val_loss: 1.4544 - val_accuracy: 0.3711\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.9640 - val_loss: 1.4727 - val_accuracy: 0.3763\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.9795 - val_loss: 1.5101 - val_accuracy: 0.3763\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1664 - accuracy: 0.9892 - val_loss: 1.5716 - val_accuracy: 0.3632\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.5331 - accuracy: 0.2771 - val_loss: 1.5252 - val_accuracy: 0.2763\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.4388 - accuracy: 0.4280 - val_loss: 1.5233 - val_accuracy: 0.2947\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.3202 - accuracy: 0.6027 - val_loss: 1.4867 - val_accuracy: 0.3316\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.1448 - accuracy: 0.7276 - val_loss: 1.4716 - val_accuracy: 0.3263\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.9298 - accuracy: 0.8192 - val_loss: 1.4564 - val_accuracy: 0.3447\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.7119 - accuracy: 0.8877 - val_loss: 1.4440 - val_accuracy: 0.3474\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.9345 - val_loss: 1.4570 - val_accuracy: 0.3632\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.9637 - val_loss: 1.4775 - val_accuracy: 0.3368\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.2479 - accuracy: 0.9795 - val_loss: 1.5069 - val_accuracy: 0.3316\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1657 - accuracy: 0.9868 - val_loss: 1.5429 - val_accuracy: 0.3395\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.5304 - accuracy: 0.2844 - val_loss: 1.5355 - val_accuracy: 0.2974\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.4333 - accuracy: 0.4307 - val_loss: 1.5089 - val_accuracy: 0.3026\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.3051 - accuracy: 0.6021 - val_loss: 1.4885 - val_accuracy: 0.3184\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.1195 - accuracy: 0.7323 - val_loss: 1.4442 - val_accuracy: 0.3684\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.9003 - accuracy: 0.8171 - val_loss: 1.4204 - val_accuracy: 0.3553\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6849 - accuracy: 0.8853 - val_loss: 1.4023 - val_accuracy: 0.3921\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.9350 - val_loss: 1.4069 - val_accuracy: 0.3842\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3462 - accuracy: 0.9637 - val_loss: 1.4372 - val_accuracy: 0.3711\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.2351 - accuracy: 0.9772 - val_loss: 1.4489 - val_accuracy: 0.3658\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1559 - accuracy: 0.9868 - val_loss: 1.4839 - val_accuracy: 0.3658\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.5292 - accuracy: 0.2932 - val_loss: 1.5342 - val_accuracy: 0.2737\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.4322 - accuracy: 0.4371 - val_loss: 1.5203 - val_accuracy: 0.2947\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.3062 - accuracy: 0.6170 - val_loss: 1.5119 - val_accuracy: 0.3079\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.1192 - accuracy: 0.7390 - val_loss: 1.5129 - val_accuracy: 0.3237\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.9016 - accuracy: 0.8189 - val_loss: 1.4849 - val_accuracy: 0.3184\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.8894 - val_loss: 1.4854 - val_accuracy: 0.3237\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.9336 - val_loss: 1.5099 - val_accuracy: 0.3368\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3435 - accuracy: 0.9652 - val_loss: 1.5418 - val_accuracy: 0.3395\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.2318 - accuracy: 0.9804 - val_loss: 1.5857 - val_accuracy: 0.3421\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1526 - accuracy: 0.9895 - val_loss: 1.6480 - val_accuracy: 0.3368\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.5303 - accuracy: 0.2879 - val_loss: 1.5309 - val_accuracy: 0.2895\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.4316 - accuracy: 0.4386 - val_loss: 1.5164 - val_accuracy: 0.2763\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.3002 - accuracy: 0.6112 - val_loss: 1.4988 - val_accuracy: 0.2921\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.1094 - accuracy: 0.7437 - val_loss: 1.4645 - val_accuracy: 0.3368\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.8828 - accuracy: 0.8335 - val_loss: 1.4476 - val_accuracy: 0.3500\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6637 - accuracy: 0.9032 - val_loss: 1.4668 - val_accuracy: 0.3553\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.9424 - val_loss: 1.4719 - val_accuracy: 0.3737\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.9687 - val_loss: 1.5072 - val_accuracy: 0.3684\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.2189 - accuracy: 0.9807 - val_loss: 1.5384 - val_accuracy: 0.3605\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1430 - accuracy: 0.9883 - val_loss: 1.5844 - val_accuracy: 0.3605\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.5325 - accuracy: 0.2838 - val_loss: 1.5192 - val_accuracy: 0.3053\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.4319 - accuracy: 0.4444 - val_loss: 1.5157 - val_accuracy: 0.2921\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.2978 - accuracy: 0.6088 - val_loss: 1.4886 - val_accuracy: 0.3289\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.1054 - accuracy: 0.7382 - val_loss: 1.4755 - val_accuracy: 0.3263\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.8804 - accuracy: 0.8277 - val_loss: 1.4666 - val_accuracy: 0.3526\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6608 - accuracy: 0.9005 - val_loss: 1.4552 - val_accuracy: 0.3553\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.9456 - val_loss: 1.4709 - val_accuracy: 0.3684\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.9699 - val_loss: 1.5065 - val_accuracy: 0.3474\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.2146 - accuracy: 0.9824 - val_loss: 1.5457 - val_accuracy: 0.3474\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1391 - accuracy: 0.9898 - val_loss: 1.5869 - val_accuracy: 0.3632\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.5259 - accuracy: 0.2920 - val_loss: 1.5230 - val_accuracy: 0.2711\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.4284 - accuracy: 0.4327 - val_loss: 1.5262 - val_accuracy: 0.3079\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.2939 - accuracy: 0.6267 - val_loss: 1.5034 - val_accuracy: 0.3211\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.0981 - accuracy: 0.7414 - val_loss: 1.4896 - val_accuracy: 0.3263\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.8692 - accuracy: 0.8423 - val_loss: 1.4813 - val_accuracy: 0.3237\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6488 - accuracy: 0.8967 - val_loss: 1.4964 - val_accuracy: 0.3447\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.9435 - val_loss: 1.5233 - val_accuracy: 0.3421\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3134 - accuracy: 0.9684 - val_loss: 1.5729 - val_accuracy: 0.3342\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.2070 - accuracy: 0.9824 - val_loss: 1.6042 - val_accuracy: 0.3421\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1333 - accuracy: 0.9895 - val_loss: 1.6658 - val_accuracy: 0.3526\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.5300 - accuracy: 0.2917 - val_loss: 1.5281 - val_accuracy: 0.2579\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.4283 - accuracy: 0.4447 - val_loss: 1.5119 - val_accuracy: 0.3053\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.2914 - accuracy: 0.6243 - val_loss: 1.4902 - val_accuracy: 0.3237\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.0916 - accuracy: 0.7519 - val_loss: 1.4713 - val_accuracy: 0.3342\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.8628 - accuracy: 0.8365 - val_loss: 1.4617 - val_accuracy: 0.3447\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6397 - accuracy: 0.9023 - val_loss: 1.4630 - val_accuracy: 0.3737\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.9497 - val_loss: 1.4910 - val_accuracy: 0.3605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.9687 - val_loss: 1.5162 - val_accuracy: 0.3658\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.2014 - accuracy: 0.9839 - val_loss: 1.5568 - val_accuracy: 0.3553\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1302 - accuracy: 0.9906 - val_loss: 1.6135 - val_accuracy: 0.3447\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.5303 - accuracy: 0.2917 - val_loss: 1.5252 - val_accuracy: 0.2632\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.4262 - accuracy: 0.4468 - val_loss: 1.5136 - val_accuracy: 0.2868\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.2869 - accuracy: 0.6103 - val_loss: 1.4980 - val_accuracy: 0.3105\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.0846 - accuracy: 0.7583 - val_loss: 1.4773 - val_accuracy: 0.3263\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.8491 - accuracy: 0.8487 - val_loss: 1.4573 - val_accuracy: 0.3368\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6228 - accuracy: 0.9108 - val_loss: 1.4731 - val_accuracy: 0.3579\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.9470 - val_loss: 1.4938 - val_accuracy: 0.3526\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.2906 - accuracy: 0.9745 - val_loss: 1.5301 - val_accuracy: 0.3816\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1887 - accuracy: 0.9836 - val_loss: 1.5776 - val_accuracy: 0.3579\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1203 - accuracy: 0.9918 - val_loss: 1.6340 - val_accuracy: 0.3474\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.5280 - accuracy: 0.2879 - val_loss: 1.5337 - val_accuracy: 0.2868\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.4282 - accuracy: 0.4324 - val_loss: 1.5106 - val_accuracy: 0.3211\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.2873 - accuracy: 0.6305 - val_loss: 1.4830 - val_accuracy: 0.3211\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.0797 - accuracy: 0.7417 - val_loss: 1.4451 - val_accuracy: 0.3447\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.8435 - accuracy: 0.8394 - val_loss: 1.4226 - val_accuracy: 0.3605\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.6182 - accuracy: 0.9046 - val_loss: 1.4198 - val_accuracy: 0.3816\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.9549 - val_loss: 1.4370 - val_accuracy: 0.3895\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2893 - accuracy: 0.9763 - val_loss: 1.4635 - val_accuracy: 0.4026\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1890 - accuracy: 0.9848 - val_loss: 1.5018 - val_accuracy: 0.3737\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.1201 - accuracy: 0.9901 - val_loss: 1.5435 - val_accuracy: 0.3763\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.5327 - accuracy: 0.2958 - val_loss: 1.5465 - val_accuracy: 0.2842\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.4247 - accuracy: 0.4549 - val_loss: 1.5045 - val_accuracy: 0.3079\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.2802 - accuracy: 0.6232 - val_loss: 1.4880 - val_accuracy: 0.3211\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.0686 - accuracy: 0.7592 - val_loss: 1.4526 - val_accuracy: 0.3316\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.8270 - accuracy: 0.8566 - val_loss: 1.4559 - val_accuracy: 0.3237\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5996 - accuracy: 0.9166 - val_loss: 1.4607 - val_accuracy: 0.3342\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.9532 - val_loss: 1.4699 - val_accuracy: 0.3316\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.2748 - accuracy: 0.9743 - val_loss: 1.5042 - val_accuracy: 0.3368\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1769 - accuracy: 0.9848 - val_loss: 1.5508 - val_accuracy: 0.3368\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1119 - accuracy: 0.9912 - val_loss: 1.6147 - val_accuracy: 0.3342\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.5281 - accuracy: 0.2873 - val_loss: 1.5330 - val_accuracy: 0.2737\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.4256 - accuracy: 0.4593 - val_loss: 1.5132 - val_accuracy: 0.2921\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.2799 - accuracy: 0.6273 - val_loss: 1.5100 - val_accuracy: 0.2921\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.0702 - accuracy: 0.7618 - val_loss: 1.4659 - val_accuracy: 0.3132\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.8282 - accuracy: 0.8499 - val_loss: 1.4452 - val_accuracy: 0.3105\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.6024 - accuracy: 0.9166 - val_loss: 1.4603 - val_accuracy: 0.3316\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.9549 - val_loss: 1.4803 - val_accuracy: 0.3342\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2730 - accuracy: 0.9769 - val_loss: 1.5123 - val_accuracy: 0.3526\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1744 - accuracy: 0.9880 - val_loss: 1.5668 - val_accuracy: 0.3474\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1091 - accuracy: 0.9924 - val_loss: 1.6131 - val_accuracy: 0.3553\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.5302 - accuracy: 0.2882 - val_loss: 1.5503 - val_accuracy: 0.2684\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.4267 - accuracy: 0.4503 - val_loss: 1.5161 - val_accuracy: 0.2789\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.2772 - accuracy: 0.6325 - val_loss: 1.4903 - val_accuracy: 0.3289\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.0630 - accuracy: 0.7613 - val_loss: 1.4575 - val_accuracy: 0.3474\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.8181 - accuracy: 0.8587 - val_loss: 1.4515 - val_accuracy: 0.3553\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5891 - accuracy: 0.9184 - val_loss: 1.4569 - val_accuracy: 0.3711\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4013 - accuracy: 0.9538 - val_loss: 1.4881 - val_accuracy: 0.3684\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2626 - accuracy: 0.9775 - val_loss: 1.5203 - val_accuracy: 0.3500\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.1673 - accuracy: 0.9877 - val_loss: 1.5645 - val_accuracy: 0.3395\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.1043 - accuracy: 0.9941 - val_loss: 1.6186 - val_accuracy: 0.3605\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.5258 - accuracy: 0.2937 - val_loss: 1.5294 - val_accuracy: 0.2737\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.4173 - accuracy: 0.4538 - val_loss: 1.4956 - val_accuracy: 0.3079\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.2647 - accuracy: 0.6413 - val_loss: 1.4750 - val_accuracy: 0.3474\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.0456 - accuracy: 0.7692 - val_loss: 1.4513 - val_accuracy: 0.3500\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.7997 - accuracy: 0.8590 - val_loss: 1.4223 - val_accuracy: 0.3632\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5745 - accuracy: 0.9225 - val_loss: 1.4325 - val_accuracy: 0.3605\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.3908 - accuracy: 0.9567 - val_loss: 1.4564 - val_accuracy: 0.3658\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2563 - accuracy: 0.9772 - val_loss: 1.4935 - val_accuracy: 0.3553\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1630 - accuracy: 0.9871 - val_loss: 1.5396 - val_accuracy: 0.3526\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9915 - val_loss: 1.5931 - val_accuracy: 0.3500\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.5300 - accuracy: 0.2929 - val_loss: 1.5282 - val_accuracy: 0.2737\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.4203 - accuracy: 0.4579 - val_loss: 1.5188 - val_accuracy: 0.2921\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.2684 - accuracy: 0.6437 - val_loss: 1.4859 - val_accuracy: 0.3316\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.0481 - accuracy: 0.7665 - val_loss: 1.4626 - val_accuracy: 0.3421\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.8005 - accuracy: 0.8616 - val_loss: 1.4472 - val_accuracy: 0.3816\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5712 - accuracy: 0.9239 - val_loss: 1.4511 - val_accuracy: 0.3711\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3868 - accuracy: 0.9599 - val_loss: 1.4723 - val_accuracy: 0.3711\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2512 - accuracy: 0.9760 - val_loss: 1.5085 - val_accuracy: 0.3658\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.1578 - accuracy: 0.9877 - val_loss: 1.5648 - val_accuracy: 0.3658\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0972 - accuracy: 0.9936 - val_loss: 1.6155 - val_accuracy: 0.3658\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.5282 - accuracy: 0.2970 - val_loss: 1.5256 - val_accuracy: 0.2816\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.4212 - accuracy: 0.4465 - val_loss: 1.5116 - val_accuracy: 0.2868\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.2665 - accuracy: 0.6270 - val_loss: 1.4936 - val_accuracy: 0.3079\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.0465 - accuracy: 0.7697 - val_loss: 1.4808 - val_accuracy: 0.3237\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.7989 - accuracy: 0.8619 - val_loss: 1.4766 - val_accuracy: 0.3158\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5687 - accuracy: 0.9257 - val_loss: 1.4948 - val_accuracy: 0.3158\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3839 - accuracy: 0.9555 - val_loss: 1.5152 - val_accuracy: 0.3211\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.9789 - val_loss: 1.5620 - val_accuracy: 0.3263\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.1567 - accuracy: 0.9895 - val_loss: 1.6279 - val_accuracy: 0.3342\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0967 - accuracy: 0.9950 - val_loss: 1.6837 - val_accuracy: 0.3132\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.5249 - accuracy: 0.2943 - val_loss: 1.5297 - val_accuracy: 0.2658\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.4165 - accuracy: 0.4640 - val_loss: 1.5198 - val_accuracy: 0.2895\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.2633 - accuracy: 0.6460 - val_loss: 1.4879 - val_accuracy: 0.3342\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.0400 - accuracy: 0.7709 - val_loss: 1.4709 - val_accuracy: 0.3237\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.7915 - accuracy: 0.8563 - val_loss: 1.4480 - val_accuracy: 0.3368\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5618 - accuracy: 0.9263 - val_loss: 1.4552 - val_accuracy: 0.3526\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3777 - accuracy: 0.9628 - val_loss: 1.4798 - val_accuracy: 0.3553\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2438 - accuracy: 0.9798 - val_loss: 1.5149 - val_accuracy: 0.3395\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.1528 - accuracy: 0.9886 - val_loss: 1.5703 - val_accuracy: 0.3605\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0933 - accuracy: 0.9941 - val_loss: 1.6355 - val_accuracy: 0.3447\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.5305 - accuracy: 0.2926 - val_loss: 1.5355 - val_accuracy: 0.2789\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.4195 - accuracy: 0.4710 - val_loss: 1.5144 - val_accuracy: 0.2868\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.2596 - accuracy: 0.6448 - val_loss: 1.4917 - val_accuracy: 0.3237\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.0336 - accuracy: 0.7785 - val_loss: 1.4788 - val_accuracy: 0.3421\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.7791 - accuracy: 0.8666 - val_loss: 1.4705 - val_accuracy: 0.3526\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5472 - accuracy: 0.9280 - val_loss: 1.4807 - val_accuracy: 0.3737\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3642 - accuracy: 0.9605 - val_loss: 1.5284 - val_accuracy: 0.3526\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2331 - accuracy: 0.9804 - val_loss: 1.5593 - val_accuracy: 0.3605\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9886 - val_loss: 1.6079 - val_accuracy: 0.3605\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0881 - accuracy: 0.9939 - val_loss: 1.6770 - val_accuracy: 0.3553\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.5268 - accuracy: 0.2847 - val_loss: 1.5433 - val_accuracy: 0.2632\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.4124 - accuracy: 0.4535 - val_loss: 1.5046 - val_accuracy: 0.3132\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.2488 - accuracy: 0.6571 - val_loss: 1.4921 - val_accuracy: 0.3447\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.0166 - accuracy: 0.7861 - val_loss: 1.4594 - val_accuracy: 0.3105\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.7635 - accuracy: 0.8730 - val_loss: 1.4580 - val_accuracy: 0.3184\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5360 - accuracy: 0.9318 - val_loss: 1.4734 - val_accuracy: 0.3263\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3551 - accuracy: 0.9637 - val_loss: 1.5006 - val_accuracy: 0.3447\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2272 - accuracy: 0.9786 - val_loss: 1.5406 - val_accuracy: 0.3632\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.1420 - accuracy: 0.9912 - val_loss: 1.5958 - val_accuracy: 0.3474\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0866 - accuracy: 0.9933 - val_loss: 1.6501 - val_accuracy: 0.3553\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.5273 - accuracy: 0.2990 - val_loss: 1.5221 - val_accuracy: 0.3000\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.4111 - accuracy: 0.4734 - val_loss: 1.5351 - val_accuracy: 0.2842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.2493 - accuracy: 0.6568 - val_loss: 1.4857 - val_accuracy: 0.3237\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.0151 - accuracy: 0.7771 - val_loss: 1.4460 - val_accuracy: 0.3368\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.7599 - accuracy: 0.8719 - val_loss: 1.4390 - val_accuracy: 0.3368\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.9295 - val_loss: 1.4418 - val_accuracy: 0.3421\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3499 - accuracy: 0.9605 - val_loss: 1.4698 - val_accuracy: 0.3553\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2222 - accuracy: 0.9813 - val_loss: 1.4947 - val_accuracy: 0.3474\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.1356 - accuracy: 0.9909 - val_loss: 1.5460 - val_accuracy: 0.3289\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0819 - accuracy: 0.9953 - val_loss: 1.6020 - val_accuracy: 0.3500\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.5268 - accuracy: 0.2894 - val_loss: 1.5220 - val_accuracy: 0.2789\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.4129 - accuracy: 0.4602 - val_loss: 1.5061 - val_accuracy: 0.2868\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.2469 - accuracy: 0.6562 - val_loss: 1.4772 - val_accuracy: 0.3158\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.0079 - accuracy: 0.7803 - val_loss: 1.4553 - val_accuracy: 0.3237\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.7516 - accuracy: 0.8742 - val_loss: 1.4459 - val_accuracy: 0.3447\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5205 - accuracy: 0.9350 - val_loss: 1.4522 - val_accuracy: 0.3553\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3404 - accuracy: 0.9652 - val_loss: 1.4850 - val_accuracy: 0.3395\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2138 - accuracy: 0.9822 - val_loss: 1.5307 - val_accuracy: 0.3395\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.1306 - accuracy: 0.9915 - val_loss: 1.5991 - val_accuracy: 0.3421\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0784 - accuracy: 0.9941 - val_loss: 1.6473 - val_accuracy: 0.3500\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.5312 - accuracy: 0.2929 - val_loss: 1.5289 - val_accuracy: 0.2711\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.4145 - accuracy: 0.4497 - val_loss: 1.5064 - val_accuracy: 0.3000\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.2505 - accuracy: 0.6556 - val_loss: 1.4932 - val_accuracy: 0.3316\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.0118 - accuracy: 0.7879 - val_loss: 1.4656 - val_accuracy: 0.3368\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.7509 - accuracy: 0.8830 - val_loss: 1.4470 - val_accuracy: 0.3316\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.9374 - val_loss: 1.4513 - val_accuracy: 0.3368\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3371 - accuracy: 0.9649 - val_loss: 1.4869 - val_accuracy: 0.3605\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2127 - accuracy: 0.9819 - val_loss: 1.5223 - val_accuracy: 0.3632\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.1302 - accuracy: 0.9883 - val_loss: 1.5668 - val_accuracy: 0.3474\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0787 - accuracy: 0.9939 - val_loss: 1.6173 - val_accuracy: 0.3579\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.5315 - accuracy: 0.2829 - val_loss: 1.5229 - val_accuracy: 0.2763\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.4134 - accuracy: 0.4710 - val_loss: 1.5071 - val_accuracy: 0.2974\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.2426 - accuracy: 0.6612 - val_loss: 1.4800 - val_accuracy: 0.3368\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.0009 - accuracy: 0.7835 - val_loss: 1.4602 - val_accuracy: 0.3342\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.7405 - accuracy: 0.8730 - val_loss: 1.4524 - val_accuracy: 0.3526\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.9318 - val_loss: 1.4645 - val_accuracy: 0.3474\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3329 - accuracy: 0.9702 - val_loss: 1.5029 - val_accuracy: 0.3395\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2086 - accuracy: 0.9836 - val_loss: 1.5444 - val_accuracy: 0.3395\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.1262 - accuracy: 0.9915 - val_loss: 1.6161 - val_accuracy: 0.3474\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0757 - accuracy: 0.9944 - val_loss: 1.6680 - val_accuracy: 0.3263\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.5272 - accuracy: 0.2914 - val_loss: 1.5214 - val_accuracy: 0.3000\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.4095 - accuracy: 0.4585 - val_loss: 1.5261 - val_accuracy: 0.2789\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.2378 - accuracy: 0.6542 - val_loss: 1.4778 - val_accuracy: 0.3316\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.9949 - accuracy: 0.7926 - val_loss: 1.4711 - val_accuracy: 0.3053\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.7334 - accuracy: 0.8786 - val_loss: 1.4457 - val_accuracy: 0.3526\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9350 - val_loss: 1.4606 - val_accuracy: 0.3447\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3253 - accuracy: 0.9666 - val_loss: 1.4905 - val_accuracy: 0.3553\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2013 - accuracy: 0.9824 - val_loss: 1.5361 - val_accuracy: 0.3684\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.1213 - accuracy: 0.9898 - val_loss: 1.5794 - val_accuracy: 0.3579\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.9965 - val_loss: 1.6559 - val_accuracy: 0.3632\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.5244 - accuracy: 0.2929 - val_loss: 1.5337 - val_accuracy: 0.2763\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.4070 - accuracy: 0.4731 - val_loss: 1.5114 - val_accuracy: 0.3079\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.2311 - accuracy: 0.6755 - val_loss: 1.4809 - val_accuracy: 0.3263\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.9822 - accuracy: 0.8022 - val_loss: 1.4586 - val_accuracy: 0.3447\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.7160 - accuracy: 0.8891 - val_loss: 1.4554 - val_accuracy: 0.3605\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4857 - accuracy: 0.9400 - val_loss: 1.4601 - val_accuracy: 0.3526\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3110 - accuracy: 0.9705 - val_loss: 1.4881 - val_accuracy: 0.3658\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.1910 - accuracy: 0.9845 - val_loss: 1.5346 - val_accuracy: 0.3605\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.1142 - accuracy: 0.9918 - val_loss: 1.5912 - val_accuracy: 0.3395\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0674 - accuracy: 0.9962 - val_loss: 1.6484 - val_accuracy: 0.3553\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.5270 - accuracy: 0.2888 - val_loss: 1.5222 - val_accuracy: 0.2684\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.4089 - accuracy: 0.4687 - val_loss: 1.5014 - val_accuracy: 0.3237\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.2334 - accuracy: 0.6788 - val_loss: 1.4770 - val_accuracy: 0.3211\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.9855 - accuracy: 0.7952 - val_loss: 1.4535 - val_accuracy: 0.3368\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.7185 - accuracy: 0.8915 - val_loss: 1.4474 - val_accuracy: 0.3395\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.9383 - val_loss: 1.4750 - val_accuracy: 0.3632\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3097 - accuracy: 0.9693 - val_loss: 1.4977 - val_accuracy: 0.3789\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.1899 - accuracy: 0.9848 - val_loss: 1.5517 - val_accuracy: 0.3632\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.1132 - accuracy: 0.9936 - val_loss: 1.6127 - val_accuracy: 0.3737\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.9944 - val_loss: 1.6735 - val_accuracy: 0.3605\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.5259 - accuracy: 0.2876 - val_loss: 1.5573 - val_accuracy: 0.2789\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.4085 - accuracy: 0.4906 - val_loss: 1.5021 - val_accuracy: 0.3053\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.2312 - accuracy: 0.6592 - val_loss: 1.4829 - val_accuracy: 0.3132\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.9850 - accuracy: 0.7949 - val_loss: 1.4507 - val_accuracy: 0.3474\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.7194 - accuracy: 0.8771 - val_loss: 1.4429 - val_accuracy: 0.3684\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4870 - accuracy: 0.9383 - val_loss: 1.4752 - val_accuracy: 0.3737\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3117 - accuracy: 0.9696 - val_loss: 1.4960 - val_accuracy: 0.3737\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.1900 - accuracy: 0.9848 - val_loss: 1.5393 - val_accuracy: 0.3658\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.1123 - accuracy: 0.9930 - val_loss: 1.6085 - val_accuracy: 0.3605\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 0.9968 - val_loss: 1.6681 - val_accuracy: 0.3763\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.5323 - accuracy: 0.2794 - val_loss: 1.5304 - val_accuracy: 0.2816\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.4078 - accuracy: 0.4590 - val_loss: 1.5171 - val_accuracy: 0.3105\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.2270 - accuracy: 0.6779 - val_loss: 1.4739 - val_accuracy: 0.3342\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.9765 - accuracy: 0.8043 - val_loss: 1.4495 - val_accuracy: 0.3474\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.7072 - accuracy: 0.8862 - val_loss: 1.4389 - val_accuracy: 0.3737\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.9435 - val_loss: 1.4668 - val_accuracy: 0.3579\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3008 - accuracy: 0.9713 - val_loss: 1.5077 - val_accuracy: 0.3711\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.1826 - accuracy: 0.9865 - val_loss: 1.5652 - val_accuracy: 0.3684\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.1085 - accuracy: 0.9930 - val_loss: 1.6281 - val_accuracy: 0.3658\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.9956 - val_loss: 1.6929 - val_accuracy: 0.3605\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.5321 - accuracy: 0.2809 - val_loss: 1.5357 - val_accuracy: 0.2605\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.4069 - accuracy: 0.4658 - val_loss: 1.5233 - val_accuracy: 0.2816\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.2248 - accuracy: 0.6673 - val_loss: 1.4909 - val_accuracy: 0.3211\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.9729 - accuracy: 0.8078 - val_loss: 1.4692 - val_accuracy: 0.3342\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.7031 - accuracy: 0.8906 - val_loss: 1.4656 - val_accuracy: 0.3474\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.9450 - val_loss: 1.4975 - val_accuracy: 0.3500\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2971 - accuracy: 0.9728 - val_loss: 1.5252 - val_accuracy: 0.3737\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.1797 - accuracy: 0.9857 - val_loss: 1.5684 - val_accuracy: 0.3763\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.1048 - accuracy: 0.9921 - val_loss: 1.6341 - val_accuracy: 0.3684\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.9968 - val_loss: 1.6862 - val_accuracy: 0.3605\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 1s 7ms/step - loss: 1.5289 - accuracy: 0.2926 - val_loss: 1.5555 - val_accuracy: 0.2763\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.4079 - accuracy: 0.4590 - val_loss: 1.5161 - val_accuracy: 0.2895\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.2250 - accuracy: 0.6685 - val_loss: 1.4856 - val_accuracy: 0.3421\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.9697 - accuracy: 0.8063 - val_loss: 1.4629 - val_accuracy: 0.3526\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.6966 - accuracy: 0.8932 - val_loss: 1.4590 - val_accuracy: 0.3421\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.9479 - val_loss: 1.4835 - val_accuracy: 0.3526\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2909 - accuracy: 0.9734 - val_loss: 1.5201 - val_accuracy: 0.3474\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.1741 - accuracy: 0.9860 - val_loss: 1.5681 - val_accuracy: 0.3500\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.1019 - accuracy: 0.9936 - val_loss: 1.6255 - val_accuracy: 0.3474\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.9971 - val_loss: 1.6977 - val_accuracy: 0.3395\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.5264 - accuracy: 0.2914 - val_loss: 1.5331 - val_accuracy: 0.2816\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.4020 - accuracy: 0.4772 - val_loss: 1.5030 - val_accuracy: 0.2974\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.2121 - accuracy: 0.6829 - val_loss: 1.4722 - val_accuracy: 0.3289\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.9520 - accuracy: 0.8174 - val_loss: 1.4653 - val_accuracy: 0.3342\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.6786 - accuracy: 0.8956 - val_loss: 1.4485 - val_accuracy: 0.3684\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.9508 - val_loss: 1.4685 - val_accuracy: 0.3763\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2782 - accuracy: 0.9745 - val_loss: 1.5131 - val_accuracy: 0.3632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.1669 - accuracy: 0.9865 - val_loss: 1.5701 - val_accuracy: 0.3658\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0970 - accuracy: 0.9927 - val_loss: 1.6275 - val_accuracy: 0.3500\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.9959 - val_loss: 1.6970 - val_accuracy: 0.3632\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.5254 - accuracy: 0.2891 - val_loss: 1.5310 - val_accuracy: 0.2737\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.4042 - accuracy: 0.4710 - val_loss: 1.5213 - val_accuracy: 0.3053\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.2177 - accuracy: 0.6820 - val_loss: 1.4822 - val_accuracy: 0.3263\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.9556 - accuracy: 0.8122 - val_loss: 1.4696 - val_accuracy: 0.3684\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.6800 - accuracy: 0.8979 - val_loss: 1.4635 - val_accuracy: 0.3632\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.9541 - val_loss: 1.4850 - val_accuracy: 0.3605\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2751 - accuracy: 0.9783 - val_loss: 1.5071 - val_accuracy: 0.3658\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.1636 - accuracy: 0.9865 - val_loss: 1.5576 - val_accuracy: 0.3658\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0948 - accuracy: 0.9915 - val_loss: 1.6132 - val_accuracy: 0.3632\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.9971 - val_loss: 1.6817 - val_accuracy: 0.3632\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.5264 - accuracy: 0.2923 - val_loss: 1.5313 - val_accuracy: 0.2658\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.3981 - accuracy: 0.4748 - val_loss: 1.4972 - val_accuracy: 0.2974\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.2052 - accuracy: 0.6902 - val_loss: 1.4700 - val_accuracy: 0.3289\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.9405 - accuracy: 0.8177 - val_loss: 1.4537 - val_accuracy: 0.3289\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.6638 - accuracy: 0.9049 - val_loss: 1.4424 - val_accuracy: 0.3368\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.9561 - val_loss: 1.4653 - val_accuracy: 0.3474\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2653 - accuracy: 0.9783 - val_loss: 1.5098 - val_accuracy: 0.3421\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.1561 - accuracy: 0.9889 - val_loss: 1.5633 - val_accuracy: 0.3447\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0898 - accuracy: 0.9941 - val_loss: 1.6248 - val_accuracy: 0.3395\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0510 - accuracy: 0.9968 - val_loss: 1.6865 - val_accuracy: 0.3342\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 5ms/step - loss: 1.5267 - accuracy: 0.2844 - val_loss: 1.5455 - val_accuracy: 0.2553\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.4027 - accuracy: 0.4579 - val_loss: 1.5022 - val_accuracy: 0.3263\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.2105 - accuracy: 0.6834 - val_loss: 1.4793 - val_accuracy: 0.3289\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.9454 - accuracy: 0.8075 - val_loss: 1.4603 - val_accuracy: 0.3263\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.6685 - accuracy: 0.9011 - val_loss: 1.4610 - val_accuracy: 0.3316\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.9491 - val_loss: 1.4751 - val_accuracy: 0.3316\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.2688 - accuracy: 0.9751 - val_loss: 1.5043 - val_accuracy: 0.3395\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.1589 - accuracy: 0.9871 - val_loss: 1.5476 - val_accuracy: 0.3447\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0920 - accuracy: 0.9936 - val_loss: 1.6076 - val_accuracy: 0.3447\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0522 - accuracy: 0.9968 - val_loss: 1.6860 - val_accuracy: 0.3500\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.5259 - accuracy: 0.2970 - val_loss: 1.5210 - val_accuracy: 0.2763\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.3950 - accuracy: 0.5076 - val_loss: 1.5270 - val_accuracy: 0.2921\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.1963 - accuracy: 0.6826 - val_loss: 1.4755 - val_accuracy: 0.3237\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.9277 - accuracy: 0.8183 - val_loss: 1.4464 - val_accuracy: 0.3421\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.6533 - accuracy: 0.8996 - val_loss: 1.4573 - val_accuracy: 0.3553\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.9535 - val_loss: 1.4857 - val_accuracy: 0.3737\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2615 - accuracy: 0.9763 - val_loss: 1.5176 - val_accuracy: 0.3842\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.1539 - accuracy: 0.9903 - val_loss: 1.5726 - val_accuracy: 0.3816\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0888 - accuracy: 0.9941 - val_loss: 1.6454 - val_accuracy: 0.3868\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9959 - val_loss: 1.7181 - val_accuracy: 0.3868\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.5256 - accuracy: 0.3025 - val_loss: 1.5282 - val_accuracy: 0.2737\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.3966 - accuracy: 0.4748 - val_loss: 1.5058 - val_accuracy: 0.3000\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.1963 - accuracy: 0.6861 - val_loss: 1.4779 - val_accuracy: 0.3132\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.9262 - accuracy: 0.8116 - val_loss: 1.4630 - val_accuracy: 0.3211\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.6503 - accuracy: 0.9099 - val_loss: 1.4717 - val_accuracy: 0.3263\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.9526 - val_loss: 1.4897 - val_accuracy: 0.3395\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2554 - accuracy: 0.9789 - val_loss: 1.5236 - val_accuracy: 0.3500\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.1486 - accuracy: 0.9868 - val_loss: 1.5684 - val_accuracy: 0.3474\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0843 - accuracy: 0.9950 - val_loss: 1.6348 - val_accuracy: 0.3474\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9974 - val_loss: 1.6933 - val_accuracy: 0.3421\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.5248 - accuracy: 0.2929 - val_loss: 1.5291 - val_accuracy: 0.2789\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.3940 - accuracy: 0.4678 - val_loss: 1.4957 - val_accuracy: 0.3263\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.1916 - accuracy: 0.6867 - val_loss: 1.4698 - val_accuracy: 0.3211\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.9203 - accuracy: 0.8171 - val_loss: 1.4437 - val_accuracy: 0.3474\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.6430 - accuracy: 0.9055 - val_loss: 1.4476 - val_accuracy: 0.3474\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4139 - accuracy: 0.9538 - val_loss: 1.4751 - val_accuracy: 0.3395\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2506 - accuracy: 0.9751 - val_loss: 1.5062 - val_accuracy: 0.3342\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.1467 - accuracy: 0.9886 - val_loss: 1.5614 - val_accuracy: 0.3421\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0837 - accuracy: 0.9944 - val_loss: 1.6176 - val_accuracy: 0.3368\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9982 - val_loss: 1.6980 - val_accuracy: 0.3211\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.5215 - accuracy: 0.2964 - val_loss: 1.5163 - val_accuracy: 0.2895\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.3942 - accuracy: 0.4851 - val_loss: 1.4992 - val_accuracy: 0.3053\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.1919 - accuracy: 0.6896 - val_loss: 1.4759 - val_accuracy: 0.3342\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.9194 - accuracy: 0.8230 - val_loss: 1.4509 - val_accuracy: 0.3316\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.6398 - accuracy: 0.9111 - val_loss: 1.4526 - val_accuracy: 0.3526\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.9526 - val_loss: 1.4802 - val_accuracy: 0.3553\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.9763 - val_loss: 1.5259 - val_accuracy: 0.3500\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9906 - val_loss: 1.5730 - val_accuracy: 0.3605\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0821 - accuracy: 0.9950 - val_loss: 1.6423 - val_accuracy: 0.3632\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0461 - accuracy: 0.9974 - val_loss: 1.7233 - val_accuracy: 0.3605\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.5266 - accuracy: 0.2899 - val_loss: 1.5263 - val_accuracy: 0.2684\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.3976 - accuracy: 0.5023 - val_loss: 1.5161 - val_accuracy: 0.2868\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.1974 - accuracy: 0.6981 - val_loss: 1.4912 - val_accuracy: 0.3342\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.9230 - accuracy: 0.8163 - val_loss: 1.4603 - val_accuracy: 0.3500\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.6385 - accuracy: 0.9111 - val_loss: 1.4708 - val_accuracy: 0.3263\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.9538 - val_loss: 1.4874 - val_accuracy: 0.3579\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2437 - accuracy: 0.9798 - val_loss: 1.5274 - val_accuracy: 0.3553\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.1416 - accuracy: 0.9871 - val_loss: 1.5781 - val_accuracy: 0.3526\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0798 - accuracy: 0.9944 - val_loss: 1.6493 - val_accuracy: 0.3711\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0444 - accuracy: 0.9977 - val_loss: 1.7241 - val_accuracy: 0.3711\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.5248 - accuracy: 0.2934 - val_loss: 1.5211 - val_accuracy: 0.2842\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.3930 - accuracy: 0.4962 - val_loss: 1.5091 - val_accuracy: 0.3105\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.1909 - accuracy: 0.6870 - val_loss: 1.4709 - val_accuracy: 0.3211\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.9156 - accuracy: 0.8277 - val_loss: 1.4502 - val_accuracy: 0.3395\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.6357 - accuracy: 0.9032 - val_loss: 1.4460 - val_accuracy: 0.3658\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.9549 - val_loss: 1.4736 - val_accuracy: 0.3474\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.9798 - val_loss: 1.5198 - val_accuracy: 0.3526\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.1415 - accuracy: 0.9895 - val_loss: 1.5660 - val_accuracy: 0.3553\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0791 - accuracy: 0.9956 - val_loss: 1.6281 - val_accuracy: 0.3711\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0438 - accuracy: 0.9980 - val_loss: 1.7043 - val_accuracy: 0.3553\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 1.5282 - accuracy: 0.2940 - val_loss: 1.5265 - val_accuracy: 0.2868\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.3887 - accuracy: 0.4924 - val_loss: 1.5030 - val_accuracy: 0.3500\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.1810 - accuracy: 0.7054 - val_loss: 1.4724 - val_accuracy: 0.3368\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.8985 - accuracy: 0.8268 - val_loss: 1.4592 - val_accuracy: 0.3553\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.6186 - accuracy: 0.9152 - val_loss: 1.4640 - val_accuracy: 0.3395\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.3905 - accuracy: 0.9579 - val_loss: 1.5086 - val_accuracy: 0.3526\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.2322 - accuracy: 0.9789 - val_loss: 1.5448 - val_accuracy: 0.3605\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.1324 - accuracy: 0.9903 - val_loss: 1.6021 - val_accuracy: 0.3737\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0734 - accuracy: 0.9950 - val_loss: 1.6659 - val_accuracy: 0.3474\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0400 - accuracy: 0.9980 - val_loss: 1.7521 - val_accuracy: 0.3553\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 5ms/step - loss: 1.5242 - accuracy: 0.2867 - val_loss: 1.5226 - val_accuracy: 0.2658\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.3883 - accuracy: 0.5003 - val_loss: 1.5039 - val_accuracy: 0.3053\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.1767 - accuracy: 0.7185 - val_loss: 1.4874 - val_accuracy: 0.3289\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.8939 - accuracy: 0.8303 - val_loss: 1.4412 - val_accuracy: 0.3421\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.6110 - accuracy: 0.9154 - val_loss: 1.4463 - val_accuracy: 0.3605\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.3846 - accuracy: 0.9579 - val_loss: 1.4705 - val_accuracy: 0.3500\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.2268 - accuracy: 0.9827 - val_loss: 1.5111 - val_accuracy: 0.3526\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.1291 - accuracy: 0.9903 - val_loss: 1.5701 - val_accuracy: 0.3395\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0715 - accuracy: 0.9968 - val_loss: 1.6482 - val_accuracy: 0.3500\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0393 - accuracy: 0.9974 - val_loss: 1.7164 - val_accuracy: 0.3553\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 5ms/step - loss: 1.5250 - accuracy: 0.2867 - val_loss: 1.5360 - val_accuracy: 0.2711\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.3879 - accuracy: 0.4862 - val_loss: 1.5254 - val_accuracy: 0.2789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.1746 - accuracy: 0.6943 - val_loss: 1.4750 - val_accuracy: 0.2921\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.8913 - accuracy: 0.8274 - val_loss: 1.4440 - val_accuracy: 0.3395\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.6057 - accuracy: 0.9160 - val_loss: 1.4604 - val_accuracy: 0.3421\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.3811 - accuracy: 0.9590 - val_loss: 1.4843 - val_accuracy: 0.3553\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.2246 - accuracy: 0.9801 - val_loss: 1.5280 - val_accuracy: 0.3526\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.1272 - accuracy: 0.9903 - val_loss: 1.5927 - val_accuracy: 0.3500\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0708 - accuracy: 0.9950 - val_loss: 1.6681 - val_accuracy: 0.3500\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0390 - accuracy: 0.9977 - val_loss: 1.7475 - val_accuracy: 0.3526\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 5ms/step - loss: 1.5229 - accuracy: 0.3016 - val_loss: 1.5423 - val_accuracy: 0.2684\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.3882 - accuracy: 0.4921 - val_loss: 1.5100 - val_accuracy: 0.3079\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.1742 - accuracy: 0.6963 - val_loss: 1.4705 - val_accuracy: 0.3316\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.8894 - accuracy: 0.8286 - val_loss: 1.4478 - val_accuracy: 0.3211\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.6076 - accuracy: 0.9152 - val_loss: 1.4491 - val_accuracy: 0.3342\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.3809 - accuracy: 0.9567 - val_loss: 1.4812 - val_accuracy: 0.3395\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.2252 - accuracy: 0.9786 - val_loss: 1.5228 - val_accuracy: 0.3447\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.1291 - accuracy: 0.9895 - val_loss: 1.5881 - val_accuracy: 0.3526\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0722 - accuracy: 0.9956 - val_loss: 1.6391 - val_accuracy: 0.3447\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0398 - accuracy: 0.9980 - val_loss: 1.7366 - val_accuracy: 0.3500\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 5ms/step - loss: 1.5242 - accuracy: 0.2917 - val_loss: 1.5437 - val_accuracy: 0.2658\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.3854 - accuracy: 0.4962 - val_loss: 1.5051 - val_accuracy: 0.2895\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.1665 - accuracy: 0.7001 - val_loss: 1.4670 - val_accuracy: 0.3447\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.8784 - accuracy: 0.8332 - val_loss: 1.4503 - val_accuracy: 0.3632\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.5953 - accuracy: 0.9134 - val_loss: 1.4446 - val_accuracy: 0.3658\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.3722 - accuracy: 0.9620 - val_loss: 1.4738 - val_accuracy: 0.3553\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.2187 - accuracy: 0.9822 - val_loss: 1.5176 - val_accuracy: 0.3632\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.1228 - accuracy: 0.9909 - val_loss: 1.5698 - val_accuracy: 0.3316\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.9968 - val_loss: 1.6337 - val_accuracy: 0.3316\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0368 - accuracy: 0.9982 - val_loss: 1.7151 - val_accuracy: 0.3289\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 1.5298 - accuracy: 0.2964 - val_loss: 1.5177 - val_accuracy: 0.3000\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.3875 - accuracy: 0.5170 - val_loss: 1.5017 - val_accuracy: 0.3184\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.1697 - accuracy: 0.7153 - val_loss: 1.4824 - val_accuracy: 0.3342\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.8790 - accuracy: 0.8286 - val_loss: 1.4546 - val_accuracy: 0.3579\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.5947 - accuracy: 0.9140 - val_loss: 1.4648 - val_accuracy: 0.3474\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.3699 - accuracy: 0.9640 - val_loss: 1.5151 - val_accuracy: 0.3289\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.2162 - accuracy: 0.9822 - val_loss: 1.5597 - val_accuracy: 0.3316\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.1219 - accuracy: 0.9906 - val_loss: 1.6170 - val_accuracy: 0.3368\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.9941 - val_loss: 1.7020 - val_accuracy: 0.3395\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0364 - accuracy: 0.9965 - val_loss: 1.7944 - val_accuracy: 0.3421\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 1.5280 - accuracy: 0.2870 - val_loss: 1.5528 - val_accuracy: 0.2711\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.3838 - accuracy: 0.4883 - val_loss: 1.5156 - val_accuracy: 0.3079\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.1653 - accuracy: 0.7106 - val_loss: 1.4921 - val_accuracy: 0.2789\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.8738 - accuracy: 0.8338 - val_loss: 1.4922 - val_accuracy: 0.3184\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.5883 - accuracy: 0.9228 - val_loss: 1.5127 - val_accuracy: 0.3237\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.3632 - accuracy: 0.9620 - val_loss: 1.5572 - val_accuracy: 0.3289\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.2101 - accuracy: 0.9819 - val_loss: 1.6148 - val_accuracy: 0.3211\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.9933 - val_loss: 1.6912 - val_accuracy: 0.3105\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0636 - accuracy: 0.9968 - val_loss: 1.7758 - val_accuracy: 0.3079\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0342 - accuracy: 0.9982 - val_loss: 1.8594 - val_accuracy: 0.3368\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 1.5226 - accuracy: 0.2940 - val_loss: 1.5313 - val_accuracy: 0.2711\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.3869 - accuracy: 0.5064 - val_loss: 1.5084 - val_accuracy: 0.3026\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.1672 - accuracy: 0.7095 - val_loss: 1.4747 - val_accuracy: 0.3316\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.8739 - accuracy: 0.8411 - val_loss: 1.4630 - val_accuracy: 0.3237\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.5860 - accuracy: 0.9219 - val_loss: 1.4649 - val_accuracy: 0.3605\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.3589 - accuracy: 0.9634 - val_loss: 1.4864 - val_accuracy: 0.3763\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.2073 - accuracy: 0.9830 - val_loss: 1.5535 - val_accuracy: 0.3632\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.1150 - accuracy: 0.9927 - val_loss: 1.5951 - val_accuracy: 0.3579\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0620 - accuracy: 0.9971 - val_loss: 1.6661 - val_accuracy: 0.3579\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0328 - accuracy: 0.9985 - val_loss: 1.7547 - val_accuracy: 0.3526\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 0s 5ms/step - loss: 1.5272 - accuracy: 0.2815 - val_loss: 1.5279 - val_accuracy: 0.2921\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.3849 - accuracy: 0.5167 - val_loss: 1.5045 - val_accuracy: 0.3184\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.1634 - accuracy: 0.7185 - val_loss: 1.4730 - val_accuracy: 0.3474\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.8645 - accuracy: 0.8400 - val_loss: 1.4640 - val_accuracy: 0.3447\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.5746 - accuracy: 0.9198 - val_loss: 1.4663 - val_accuracy: 0.3605\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.3500 - accuracy: 0.9658 - val_loss: 1.5090 - val_accuracy: 0.3684\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.2020 - accuracy: 0.9833 - val_loss: 1.5337 - val_accuracy: 0.3842\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.1120 - accuracy: 0.9921 - val_loss: 1.5931 - val_accuracy: 0.3868\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0603 - accuracy: 0.9965 - val_loss: 1.6808 - val_accuracy: 0.3763\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0324 - accuracy: 0.9988 - val_loss: 1.7698 - val_accuracy: 0.3737\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 1.5252 - accuracy: 0.3119 - val_loss: 1.5309 - val_accuracy: 0.2684\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.3791 - accuracy: 0.5050 - val_loss: 1.4998 - val_accuracy: 0.3158\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.1520 - accuracy: 0.7074 - val_loss: 1.4723 - val_accuracy: 0.3237\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.8556 - accuracy: 0.8429 - val_loss: 1.4474 - val_accuracy: 0.3421\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.5698 - accuracy: 0.9187 - val_loss: 1.4614 - val_accuracy: 0.3447\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.3493 - accuracy: 0.9652 - val_loss: 1.4908 - val_accuracy: 0.3763\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.2022 - accuracy: 0.9842 - val_loss: 1.5446 - val_accuracy: 0.3842\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.1106 - accuracy: 0.9939 - val_loss: 1.6429 - val_accuracy: 0.3579\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 0.9956 - val_loss: 1.7017 - val_accuracy: 0.3737\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0318 - accuracy: 0.9988 - val_loss: 1.7743 - val_accuracy: 0.3632\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 1.5255 - accuracy: 0.2946 - val_loss: 1.5366 - val_accuracy: 0.2789\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.3825 - accuracy: 0.5061 - val_loss: 1.5078 - val_accuracy: 0.3211\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.1513 - accuracy: 0.7168 - val_loss: 1.4693 - val_accuracy: 0.3289\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.8527 - accuracy: 0.8444 - val_loss: 1.4528 - val_accuracy: 0.3579\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.5640 - accuracy: 0.9236 - val_loss: 1.4667 - val_accuracy: 0.3500\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.3427 - accuracy: 0.9684 - val_loss: 1.5175 - val_accuracy: 0.3579\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.1955 - accuracy: 0.9833 - val_loss: 1.5672 - val_accuracy: 0.3605\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.1082 - accuracy: 0.9933 - val_loss: 1.6432 - val_accuracy: 0.3658\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0580 - accuracy: 0.9965 - val_loss: 1.7247 - val_accuracy: 0.3526\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0310 - accuracy: 0.9982 - val_loss: 1.8304 - val_accuracy: 0.3447\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 1.5235 - accuracy: 0.2981 - val_loss: 1.5275 - val_accuracy: 0.2816\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.3806 - accuracy: 0.5184 - val_loss: 1.5060 - val_accuracy: 0.2974\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.1499 - accuracy: 0.7235 - val_loss: 1.4698 - val_accuracy: 0.3237\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.8467 - accuracy: 0.8482 - val_loss: 1.4551 - val_accuracy: 0.3421\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.5552 - accuracy: 0.9298 - val_loss: 1.4619 - val_accuracy: 0.3395\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.3349 - accuracy: 0.9687 - val_loss: 1.5012 - val_accuracy: 0.3368\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.1900 - accuracy: 0.9845 - val_loss: 1.5683 - val_accuracy: 0.3316\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.1034 - accuracy: 0.9936 - val_loss: 1.6366 - val_accuracy: 0.3316\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0556 - accuracy: 0.9968 - val_loss: 1.7076 - val_accuracy: 0.3263\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0292 - accuracy: 0.9985 - val_loss: 1.8043 - val_accuracy: 0.3395\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 1.5223 - accuracy: 0.2984 - val_loss: 1.5226 - val_accuracy: 0.2842\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.3790 - accuracy: 0.5108 - val_loss: 1.5153 - val_accuracy: 0.3026\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.1496 - accuracy: 0.7098 - val_loss: 1.4528 - val_accuracy: 0.3289\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.8485 - accuracy: 0.8464 - val_loss: 1.4487 - val_accuracy: 0.3289\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.5601 - accuracy: 0.9254 - val_loss: 1.4473 - val_accuracy: 0.3658\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.3387 - accuracy: 0.9681 - val_loss: 1.4841 - val_accuracy: 0.3289\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.1941 - accuracy: 0.9836 - val_loss: 1.5338 - val_accuracy: 0.3500\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.1069 - accuracy: 0.9930 - val_loss: 1.5905 - val_accuracy: 0.3342\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0572 - accuracy: 0.9962 - val_loss: 1.6628 - val_accuracy: 0.3526\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.0303 - accuracy: 0.9991 - val_loss: 1.7666 - val_accuracy: 0.3579\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 1.5242 - accuracy: 0.3016 - val_loss: 1.5238 - val_accuracy: 0.2711\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.3744 - accuracy: 0.5170 - val_loss: 1.5125 - val_accuracy: 0.2737\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.1416 - accuracy: 0.7221 - val_loss: 1.4810 - val_accuracy: 0.3395\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.8335 - accuracy: 0.8543 - val_loss: 1.4686 - val_accuracy: 0.3289\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.5434 - accuracy: 0.9272 - val_loss: 1.4910 - val_accuracy: 0.3421\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.3254 - accuracy: 0.9666 - val_loss: 1.5220 - val_accuracy: 0.3605\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.1854 - accuracy: 0.9830 - val_loss: 1.5930 - val_accuracy: 0.3421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.1021 - accuracy: 0.9927 - val_loss: 1.6508 - val_accuracy: 0.3579\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0545 - accuracy: 0.9965 - val_loss: 1.7405 - val_accuracy: 0.3316\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0293 - accuracy: 0.9980 - val_loss: 1.8115 - val_accuracy: 0.3237\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 1.5217 - accuracy: 0.2996 - val_loss: 1.5218 - val_accuracy: 0.2632\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.3785 - accuracy: 0.5099 - val_loss: 1.5160 - val_accuracy: 0.3053\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 1.1466 - accuracy: 0.7232 - val_loss: 1.4747 - val_accuracy: 0.3132\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.8395 - accuracy: 0.8479 - val_loss: 1.4453 - val_accuracy: 0.3474\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.5471 - accuracy: 0.9295 - val_loss: 1.4594 - val_accuracy: 0.3342\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.3254 - accuracy: 0.9690 - val_loss: 1.4908 - val_accuracy: 0.3395\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.1826 - accuracy: 0.9862 - val_loss: 1.5346 - val_accuracy: 0.3658\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0985 - accuracy: 0.9941 - val_loss: 1.6112 - val_accuracy: 0.3579\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0522 - accuracy: 0.9962 - val_loss: 1.6866 - val_accuracy: 0.3447\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0273 - accuracy: 0.9988 - val_loss: 1.7900 - val_accuracy: 0.3474\n"
     ]
    }
   ],
   "source": [
    "maxAcc = []\n",
    "for i in range(1,100):\n",
    "    hist = testModel(i)\n",
    "    maxAcc.append(max(hist['val_accuracy']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(maxAcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f51a875a220>]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(maxAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Extremely Negative'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-338-eee201277bac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mallData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mallData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0myDictRev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mallData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'Extremely Negative'"
     ]
    }
   ],
   "source": [
    "#Looks like levels off at using 32 dimensions for LSTM...\n",
    "#Next will try using MAE\n",
    "\n",
    "allData = df.to_numpy()\n",
    "for i in range(len(allData[:,1])):\n",
    "    allData[i,1] =yDictRev[allData[i,1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleDict = {\n",
    "    'Extremely Negative':-2,\n",
    "    'Negative': -1,\n",
    "    'Neutral': 0,\n",
    "    'Positive':1,\n",
    "    'Extremely Positive':2\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-0c8f806eada1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentiment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mallData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaleDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentiment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "for i, sentiment in enumerate(allData[:,1]):\n",
    "    allData[i,1] = scaleDict[sentiment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['TRENDING: New Yorkers encounter empty supermarket shelves (pictured, Wegmans in Brooklyn), sold-out online grocers (FoodKick, MaxDelivery) as #coronavirus-fearing shoppers stock up https://t.co/Gr76pcrLWh https://t.co/ivMKMsqdT1',\n",
       "        -2],\n",
       "       [\"When I couldn't find hand sanitizer at Fred Meyer, I turned to #Amazon. But $114.97 for a 2 pack of Purell??!!Check out how  #coronavirus concerns are driving up prices. https://t.co/ygbipBflMY\",\n",
       "        1],\n",
       "       ['Find out how you can protect yourself and loved ones from #coronavirus. ?',\n",
       "        2],\n",
       "       ...,\n",
       "       [\"Asst Prof of Economics @cconces was on @NBCPhiladelphia talking about her recent research on coronavirus' impact on the economy. Watch it here (starting at :33): https://t.co/8tfYNoro5l\",\n",
       "        0],\n",
       "       [\"Gov need to do somethings instead of biar je rakyat assume 'lockdown' ke or even worst. Harini semua supermarket crowded like hell. Lagi mudah virus tu tersebar ?? #COVID2019\",\n",
       "        -2],\n",
       "       ['I and @ForestandPaper members are committed to the safety of our employees and our end-users. We are monitoring COVID-19. Rest assured that tissue manufacturers are continuing to produce and ship products.  https://t.co/qF6hclCAEq https://t.co/xyvbNsFeXA',\n",
       "        2]], dtype=object)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxWords = 10000\n",
    "samples = allData[:,0]\n",
    "tok = Tokenizer(num_words = maxWords)\n",
    "tok.fit_on_texts(samples)\n",
    "sequences = tok.texts_to_sequences(samples)\n",
    "sequences = pad_sequences(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sequences\n",
    "y = allData[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_201\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_198 (Embedding)    (None, 65, 32)            320000    \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dense_196 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 344,897\n",
      "Trainable params: 344,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "model = Sequential()\n",
    "model.add(Embedding(maxWords, 32, input_length = 65))\n",
    "model.add(LSTM(64))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.summary()\n",
    "#model.compile(optimizer = 'rmsprop', loss = 'mse', metrics = ['accuracy'])\n",
    "#model.fit(x,y,epochs = 10, validation_split = 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'rmsprop', loss = 'mse', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "95/95 [==============================] - 2s 20ms/step - loss: 0.2752 - accuracy: 0.3374 - val_loss: 1.3527 - val_accuracy: 0.2461\n",
      "Epoch 2/15\n",
      "95/95 [==============================] - 2s 20ms/step - loss: 0.2176 - accuracy: 0.3542 - val_loss: 1.1431 - val_accuracy: 0.2526\n",
      "Epoch 3/15\n",
      "95/95 [==============================] - 2s 21ms/step - loss: 0.1881 - accuracy: 0.3611 - val_loss: 1.0670 - val_accuracy: 0.2500\n",
      "Epoch 4/15\n",
      "95/95 [==============================] - 2s 21ms/step - loss: 0.1586 - accuracy: 0.3631 - val_loss: 1.1063 - val_accuracy: 0.2355\n",
      "Epoch 5/15\n",
      "95/95 [==============================] - 2s 22ms/step - loss: 0.1380 - accuracy: 0.3637 - val_loss: 1.0589 - val_accuracy: 0.2566\n",
      "Epoch 6/15\n",
      "95/95 [==============================] - 2s 21ms/step - loss: 0.1180 - accuracy: 0.3690 - val_loss: 1.0380 - val_accuracy: 0.2632\n",
      "Epoch 7/15\n",
      "95/95 [==============================] - 2s 21ms/step - loss: 0.1070 - accuracy: 0.3756 - val_loss: 1.0526 - val_accuracy: 0.2553\n",
      "Epoch 8/15\n",
      "95/95 [==============================] - 2s 21ms/step - loss: 0.0984 - accuracy: 0.3776 - val_loss: 1.0512 - val_accuracy: 0.2553\n",
      "Epoch 9/15\n",
      "95/95 [==============================] - 2s 20ms/step - loss: 0.0871 - accuracy: 0.3855 - val_loss: 1.0541 - val_accuracy: 0.2553\n",
      "Epoch 10/15\n",
      "95/95 [==============================] - 2s 20ms/step - loss: 0.0788 - accuracy: 0.3897 - val_loss: 1.1153 - val_accuracy: 0.2618\n",
      "Epoch 11/15\n",
      "95/95 [==============================] - 2s 21ms/step - loss: 0.0745 - accuracy: 0.3901 - val_loss: 1.1100 - val_accuracy: 0.2461\n",
      "Epoch 12/15\n",
      "95/95 [==============================] - 2s 21ms/step - loss: 0.0700 - accuracy: 0.3901 - val_loss: 1.0677 - val_accuracy: 0.2579\n",
      "Epoch 13/15\n",
      "95/95 [==============================] - 2s 24ms/step - loss: 0.0614 - accuracy: 0.3957 - val_loss: 1.0793 - val_accuracy: 0.2382\n",
      "Epoch 14/15\n",
      "95/95 [==============================] - 2s 21ms/step - loss: 0.0552 - accuracy: 0.3934 - val_loss: 1.1202 - val_accuracy: 0.2539\n",
      "Epoch 15/15\n",
      "95/95 [==============================] - 2s 21ms/step - loss: 0.0536 - accuracy: 0.3963 - val_loss: 1.0763 - val_accuracy: 0.2566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f51bbaf1280>"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.asarray(x).astype('float32')\n",
    "y = np.asarray(y).astype('float32')\n",
    "model.fit(x,y, epochs = 15, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['TRENDING: New Yorkers encounter empty supermarket shelves (pictured, Wegmans in Brooklyn), sold-out online grocers (FoodKick, MaxDelivery) as #coronavirus-fearing shoppers stock up https://t.co/Gr76pcrLWh https://t.co/ivMKMsqdT1',\n",
       "        0],\n",
       "       [\"When I couldn't find hand sanitizer at Fred Meyer, I turned to #Amazon. But $114.97 for a 2 pack of Purell??!!Check out how  #coronavirus concerns are driving up prices. https://t.co/ygbipBflMY\",\n",
       "        4],\n",
       "       ['Find out how you can protect yourself and loved ones from #coronavirus. ?',\n",
       "        1],\n",
       "       ...,\n",
       "       [\"Asst Prof of Economics @cconces was on @NBCPhiladelphia talking about her recent research on coronavirus' impact on the economy. Watch it here (starting at :33): https://t.co/8tfYNoro5l\",\n",
       "        3],\n",
       "       [\"Gov need to do somethings instead of biar je rakyat assume 'lockdown' ke or even worst. Harini semua supermarket crowded like hell. Lagi mudah virus tu tersebar ?? #COVID2019\",\n",
       "        0],\n",
       "       ['I and @ForestandPaper members are committed to the safety of our employees and our end-users. We are monitoring COVID-19. Rest assured that tissue manufacturers are continuing to produce and ship products.  https://t.co/qF6hclCAEq https://t.co/xyvbNsFeXA',\n",
       "        1]], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Not too great... going to try LSTM with softmax again\n",
    "data = df.to_numpy()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scaleDict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-82aa7f95b733>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrevScale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscaleDict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scaleDict' is not defined"
     ]
    }
   ],
   "source": [
    "revScale = dict([(value, key) for (key,value) in scaleDict.items()])\n",
    "for i in range(len(data[:,1])):\n",
    "    data[i,1] = yDict[data[i,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data[:,1]\n",
    "y = to_categorical(y)\n",
    "y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 60, 32)            32000     \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 128)               49664     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 82,309\n",
      "Trainable params: 82,309\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM,Bidirectional\n",
    "model = Sequential()\n",
    "model.add(Embedding(1000, 32, input_length = 60))\n",
    "model.add(Bidirectional(LSTM(64, dropout = 0.2, recurrent_dropout = 0.2)))\n",
    "model.add(Dense(5, activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxWords = 1000\n",
    "samples = allData[:,0]\n",
    "tok = Tokenizer(num_words = maxWords)\n",
    "tok.fit_on_texts(samples)\n",
    "sequences = tok.texts_to_sequences(samples)\n",
    "sequences = pad_sequences(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "107/107 [==============================] - 7s 63ms/step - loss: 1.5489 - accuracy: 0.2782 - val_loss: 1.5390 - val_accuracy: 0.2789\n",
      "Epoch 2/20\n",
      "107/107 [==============================] - 6s 59ms/step - loss: 1.4827 - accuracy: 0.3218 - val_loss: 1.5577 - val_accuracy: 0.3026\n",
      "Epoch 3/20\n",
      "107/107 [==============================] - 6s 59ms/step - loss: 1.4113 - accuracy: 0.3856 - val_loss: 1.4493 - val_accuracy: 0.3789\n",
      "Epoch 4/20\n",
      "107/107 [==============================] - 6s 59ms/step - loss: 1.3125 - accuracy: 0.4447 - val_loss: 1.4287 - val_accuracy: 0.3763\n",
      "Epoch 5/20\n",
      "107/107 [==============================] - 6s 59ms/step - loss: 1.2159 - accuracy: 0.4982 - val_loss: 1.3616 - val_accuracy: 0.4053\n",
      "Epoch 6/20\n",
      "107/107 [==============================] - 6s 59ms/step - loss: 1.1387 - accuracy: 0.5363 - val_loss: 1.3708 - val_accuracy: 0.4053\n",
      "Epoch 7/20\n",
      "107/107 [==============================] - 6s 59ms/step - loss: 1.0756 - accuracy: 0.5711 - val_loss: 1.3557 - val_accuracy: 0.4289\n",
      "Epoch 8/20\n",
      "107/107 [==============================] - 6s 59ms/step - loss: 1.0228 - accuracy: 0.5843 - val_loss: 1.3211 - val_accuracy: 0.4605\n",
      "Epoch 9/20\n",
      "107/107 [==============================] - 6s 59ms/step - loss: 0.9812 - accuracy: 0.6159 - val_loss: 1.3549 - val_accuracy: 0.4184\n",
      "Epoch 10/20\n",
      "107/107 [==============================] - 6s 59ms/step - loss: 0.9453 - accuracy: 0.6372 - val_loss: 1.3602 - val_accuracy: 0.4447\n",
      "Epoch 11/20\n",
      "107/107 [==============================] - 6s 59ms/step - loss: 0.9103 - accuracy: 0.6489 - val_loss: 1.3974 - val_accuracy: 0.4421\n",
      "Epoch 12/20\n",
      "107/107 [==============================] - 6s 60ms/step - loss: 0.8800 - accuracy: 0.6653 - val_loss: 1.4357 - val_accuracy: 0.4500\n",
      "Epoch 13/20\n",
      "107/107 [==============================] - 6s 60ms/step - loss: 0.8573 - accuracy: 0.6837 - val_loss: 1.3477 - val_accuracy: 0.4763\n",
      "Epoch 14/20\n",
      "107/107 [==============================] - 6s 59ms/step - loss: 0.8359 - accuracy: 0.6864 - val_loss: 1.4126 - val_accuracy: 0.4474\n",
      "Epoch 15/20\n",
      "107/107 [==============================] - 6s 60ms/step - loss: 0.8169 - accuracy: 0.6946 - val_loss: 1.3962 - val_accuracy: 0.4368\n",
      "Epoch 16/20\n",
      "107/107 [==============================] - 6s 59ms/step - loss: 0.7847 - accuracy: 0.7063 - val_loss: 1.3973 - val_accuracy: 0.4474\n",
      "Epoch 17/20\n",
      "107/107 [==============================] - 6s 59ms/step - loss: 0.7694 - accuracy: 0.7253 - val_loss: 1.5021 - val_accuracy: 0.4132\n",
      "Epoch 18/20\n",
      "107/107 [==============================] - 6s 59ms/step - loss: 0.7546 - accuracy: 0.7317 - val_loss: 1.5310 - val_accuracy: 0.4395\n",
      "Epoch 19/20\n",
      "107/107 [==============================] - 6s 60ms/step - loss: 0.7421 - accuracy: 0.7259 - val_loss: 1.4441 - val_accuracy: 0.4237\n",
      "Epoch 20/20\n",
      "107/107 [==============================] - 6s 60ms/step - loss: 0.7312 - accuracy: 0.7346 - val_loss: 1.5346 - val_accuracy: 0.4447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1358a6b460>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sequences,y, validation_split = 0.1, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    8,   10, 5451],\n",
       "       [   0,    0,    0, ...,    8,   10, 5454],\n",
       "       [   0,    0,    0, ...,  669,   49,   13],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,   12,    8,   10],\n",
       "       [   0,    0,    0, ...,  753,  112,  102],\n",
       "       [   0,    0,    0, ...,   12,    8,   10]], dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
